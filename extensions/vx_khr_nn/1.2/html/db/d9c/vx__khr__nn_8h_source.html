<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>OpenVX Neural Network Extension: vx_khr_nn.h Source File</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../OpenVX_170px_June16.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">OpenVX Neural Network Extension
   &#160;<span id="projectnumber">02b8d012</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('db/d9c/vx__khr__nn_8h_source.html','../../');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">vx_khr_nn.h</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/* </span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> * Copyright (c) 2012-2017 The Khronos Group Inc.</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * you may not use this file except in compliance with the License.</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> * You may obtain a copy of the License at</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> *    http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"> * See the License for the specific language governing permissions and</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment"> * limitations under the License.</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#ifndef _VX_KHR_NN_H_</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#define _VX_KHR_NN_H_</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment">/*!</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment"> * \file</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment"> * \brief The Khronos Extension for Deep Convolutional Networks Functions.</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="comment"> * \defgroup group_cnn Extension: Deep Convolutional Networks API</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="comment"> * \brief Convolutional Network Nodes.</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#define OPENVX_KHR_NN   &quot;vx_khr_nn&quot;</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &lt;VX/vx.h&gt;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="preprocessor">#ifdef  __cplusplus</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="keyword">extern</span> <span class="stringliteral">&quot;C&quot;</span> {</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment">/*==============================================================================</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment">CONVOLUTIONAL_NETWORK structs and enums</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="comment">=============================================================================*/</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="comment">/*! \brief The Neural Network Extension Library Set</span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00046"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">   46</a></span>&#160;<span class="preprocessor">#define VX_LIBRARY_KHR_NN_EXTENSION (0x1) </span></div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="comment">/*! \brief The list of Neural Network Extension Kernels.</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00051"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gad499c32ff42607fcffda9c3cca7185ef">   51</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#gad499c32ff42607fcffda9c3cca7185ef">vx_kernel_nn_ext_e</a> {<span class="comment"></span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="comment">    /*! \brief The Neural Network Extension convolution Kernel.</span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00055"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa10c8eec4ac69b37a90b34d9751aefc31">   55</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa10c8eec4ac69b37a90b34d9751aefc31">VX_KERNEL_CONVOLUTION_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x0,<span class="comment"></span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="comment">    /*! \brief The Neural Network Extension fully connected Kernel.</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00059"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa3269ace450aac7e30be256d5a3efcc8c">   59</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa3269ace450aac7e30be256d5a3efcc8c">VX_KERNEL_FULLY_CONNECTED_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x1,<span class="comment"></span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="comment">    /*! \brief The Neural Network Extension pooling Kernel.</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00063"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efad75b4eaef510d969e412aa08d2cb3edc">   63</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efad75b4eaef510d969e412aa08d2cb3edc">VX_KERNEL_POOLING_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x2,<span class="comment"></span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">    /*! \brief The Neural Network Extension softmax Kernel.</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00067"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa270b8ce654066df27b279fdec4b07bdf">   67</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa270b8ce654066df27b279fdec4b07bdf">VX_KERNEL_SOFTMAX_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x3,<span class="comment"></span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">    /*! \brief The Neural Network Extension normalization Kernel.</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00071"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa839fdec645115663c8ecd71238d5353f">   71</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa839fdec645115663c8ecd71238d5353f">VX_KERNEL_NORMALIZATION_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x4,<span class="comment"></span></div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment">    /*! \brief The Neural Network Extension activation Kernel.</span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00075"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efafcfbeeb8d83b4ae949ec8fd06c7dcc19">   75</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efafcfbeeb8d83b4ae949ec8fd06c7dcc19">VX_KERNEL_ACTIVATION_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x5,<span class="comment"></span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">    /*! \brief The Neural Network POI Pooling Kernel.</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00079"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa04b0137b6e503e303c75f38da895cfe9">   79</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa04b0137b6e503e303c75f38da895cfe9">VX_KERNEL_ROI_POOLING_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x6,<span class="comment"></span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="comment">    /*! \brief The Neural Network Extension Deconvolution Kernel.</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="comment">    * \see group_cnn</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00083"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa0993f051aa373134ea832496168d6fed">   83</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa0993f051aa373134ea832496168d6fed">VX_KERNEL_DECONVOLUTION_LAYER</a> = VX_KERNEL_BASE(VX_ID_KHRONOS, <a class="code" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>) + 0x7,</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;};</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment">/*! \brief NN extension type enums.</span></div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00089"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gae5b5a30ecdff611b248b26f65d7aa900">   89</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#gae5b5a30ecdff611b248b26f65d7aa900">vx_nn_enum_e</a></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;{</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    VX_ENUM_NN_ROUNDING_TYPE    = 0x1A,</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    VX_ENUM_NN_POOLING_TYPE = 0x1B,</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    VX_ENUM_NN_NORMALIZATION_TYPE   = 0x1C,</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE = 0x1D,</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;};</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="comment">/*! \brief down scale rounding.</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="comment"> * \details Due to different scheme of downscale size calculation in the various training frameworks. Implementation must support 2 rounding methods for down scale calculation.</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;<span class="comment"> * The floor and the ceiling. In convolution and pooling functions.</span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;<span class="comment"> * Relevant when input size is even.</span></div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00103"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">  103</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a></div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;{<span class="comment"></span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment">    /*! \brief floor rounding  */</span></div><div class="line"><a name="l00106"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6a2aa48ad506133fdf01c0bd37f6293860">  106</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6a2aa48ad506133fdf01c0bd37f6293860">VX_NN_DS_SIZE_ROUNDING_FLOOR</a> = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ROUNDING_TYPE) + 0x0,<span class="comment"></span></div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;<span class="comment">    /*! \brief ceil rounding */</span></div><div class="line"><a name="l00108"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6ad6a16dde063af1e7b3797cd5c3d58415">  108</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6ad6a16dde063af1e7b3797cd5c3d58415">VX_NN_DS_SIZE_ROUNDING_CEILING</a> = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ROUNDING_TYPE) + 0x1</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;};</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="comment">/*! \brief The Neural Network pooling type list.</span></div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="comment"> * \details kind of pooling done in pooling function</span></div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00116"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">  116</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">vx_nn_pooling_type_e</a></div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;{<span class="comment"></span></div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="comment">    /*! \brief max pooling*/</span></div><div class="line"><a name="l00119"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc">  119</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc">VX_NN_POOLING_MAX</a> = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_POOLING_TYPE) + 0x0,<span class="comment"></span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;<span class="comment">    /*! \brief average pooling*/</span></div><div class="line"><a name="l00121"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2add52234a10e4685d1958be373319741c">  121</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2add52234a10e4685d1958be373319741c">VX_NN_POOLING_AVG</a> = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_POOLING_TYPE) + 0x1</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;};</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;<span class="comment">/*! \brief The Neural Network normalization type list.</span></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00128"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ga5edc475524c86e326b56ffaa7e8eaa28">  128</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#ga5edc475524c86e326b56ffaa7e8eaa28">vx_nn_norm_type_e</a></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;{<span class="comment"></span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="comment">    /*! \brief normalization is done on same IFM*/</span></div><div class="line"><a name="l00131"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28ae67da78d606b251db59482d18ca889ae">  131</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28ae67da78d606b251db59482d18ca889ae">VX_NN_NORMALIZATION_SAME_MAP</a> = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_NORMALIZATION_TYPE) + 0x0,<span class="comment"></span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="comment">    /*! \brief Normalization is done across different IFMs*/</span></div><div class="line"><a name="l00133"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28a9cb28001c736aa33d54a839e812a40ed">  133</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28a9cb28001c736aa33d54a839e812a40ed">VX_NN_NORMALIZATION_ACROSS_MAPS</a> = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_NORMALIZATION_TYPE) + 0x1,</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;};</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment">/*! \brief The Neural Network activation functions list.</span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="comment"> * \details</span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment"> * &lt;table&gt;</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt; &lt;B&gt;Function name &lt;/B&gt; &lt;td&gt; &lt;B&gt;Mathematical definition&lt;/B&gt; &lt;td&gt; &lt;B&gt;Parameters&lt;/B&gt; &lt;td&gt; &lt;B&gt;Parameters type&lt;/B&gt;</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;logistic &lt;td&gt; \f$f(x)=1/(1+e^{-x}) \f$  &lt;td&gt;  &lt;td&gt;</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;hyperbolic tangent &lt;td&gt; \f$f(x)=a\cdot tanh(b\cdot x) \f$  &lt;td&gt; a,b  &lt;td&gt; VX_FLOAT32</span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;relu &lt;td&gt; \f$f(x)=max(0,x)\f$  &lt;td&gt;  &lt;td&gt;</span></div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;bounded relu &lt;td&gt; \f$f(x)=min(a,max(0,x)) \f$  &lt;td&gt; a  &lt;td&gt; VX_FLOAT32</span></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;soft relu &lt;td&gt; \f$f(x)=log(1+e^{x}) \f$  &lt;td&gt;  &lt;td&gt;</span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;abs &lt;td&gt; \f$f(x)=\mid x\mid \f$  &lt;td&gt;  &lt;td&gt;</span></div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;square &lt;td&gt; \f$f(x)= x^2 \f$  &lt;td&gt;  &lt;td&gt;</span></div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;square root &lt;td&gt; \f$f(x)=\sqrt{x} \f$  &lt;td&gt;  &lt;td&gt;</span></div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="comment"> * &lt;tr&gt;&lt;td&gt;linear &lt;td&gt; \f$f(x)=ax+b \f$  &lt;td&gt;  a,b  &lt;td&gt; VX_FLOAT32</span></div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="comment"> * &lt;/table&gt;</span></div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00154"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">  154</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">vx_nn_activation_function_e</a></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;{</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    VX_NN_ACTIVATION_LOGISTIC = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x0,</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;    VX_NN_ACTIVATION_HYPERBOLIC_TAN = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x1,</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    VX_NN_ACTIVATION_RELU = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x2,</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    VX_NN_ACTIVATION_BRELU = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x3,</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    VX_NN_ACTIVATION_SOFTRELU = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x4,</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;    VX_NN_ACTIVATION_ABS = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x5,</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;    VX_NN_ACTIVATION_SQUARE = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x6,</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;    VX_NN_ACTIVATION_SQRT = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x7,</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;    VX_NN_ACTIVATION_LINEAR = VX_ENUM_BASE(VX_ID_KHRONOS, VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE) + 0x8,</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;};</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment">/*! \brief The type enumeration lists all NN extension types.</span></div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00171"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ga27a8a65bf3129353d6446474b0b78164">  171</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#ga27a8a65bf3129353d6446474b0b78164">vx_nn_type_e</a> {</div><div class="line"><a name="l00172"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a411116ea30558ddbf45dc7db2074522f">  172</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a411116ea30558ddbf45dc7db2074522f">VX_TYPE_NN_CONVOLUTION_PARAMS</a>     = 0x025,<span class="comment">/*!&lt; \brief A &lt;tt&gt;\ref vx_nn_convolution_params_t&lt;/tt&gt;. */</span></div><div class="line"><a name="l00173"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a93013c97c0c22dfc6e165e636616da56">  173</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a93013c97c0c22dfc6e165e636616da56">VX_TYPE_NN_DECONVOLUTION_PARAMS</a>   = 0x026,<span class="comment">/*!&lt; \brief A &lt;tt&gt;\ref vx_nn_deconvolution_params_t&lt;/tt&gt;. */</span></div><div class="line"><a name="l00174"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164af06282ca200b459a31d85e09aec81cc1">  174</a></span>&#160;    <a class="code" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164af06282ca200b459a31d85e09aec81cc1">VX_TYPE_NN_ROI_POOL_PARAMS</a>        = 0x027,<span class="comment">/*!&lt; \brief A &lt;tt&gt;\ref vx_nn_roi_pool_params_t&lt;/tt&gt;. */</span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;};</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="comment">/*! \brief Input parameters for a convolution operation.</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00180"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html">  180</a></span>&#160;<span class="keyword">typedef</span> <span class="keyword">struct </span>_vx_nn_convolution_params_t</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;{</div><div class="line"><a name="l00182"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ae172ac2cf9d292e38af5b394b4724d64">  182</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#ae172ac2cf9d292e38af5b394b4724d64">padding_x</a>;                 <span class="comment">/*!&lt; \brief Number of elements added at each side in the x dimension of the input. */</span></div><div class="line"><a name="l00183"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ac420cbc3cb68cc9786c4050892df95a4">  183</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#ac420cbc3cb68cc9786c4050892df95a4">padding_y</a>;                 <span class="comment">/*!&lt; \brief Number of elements added at each side in the y dimension of the input. */</span></div><div class="line"><a name="l00184"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#a5fb7b1019861afc6098197139bc991bc">  184</a></span>&#160;    vx_enum <a class="code" href="../../d6/d9a/group__group__cnn.html#a5fb7b1019861afc6098197139bc991bc">overflow_policy</a>;         <span class="comment">/*!&lt; \brief A &lt;tt&gt; VX_TYPE_ENUM&lt;/tt&gt; of the &lt;tt&gt; vx_convert_policy_e&lt;/tt&gt; enumeration. */</span></div><div class="line"><a name="l00185"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#a1a3c3ebf7954bd120ed6fd91debeeb42">  185</a></span>&#160;    vx_enum <a class="code" href="../../d6/d9a/group__group__cnn.html#a1a3c3ebf7954bd120ed6fd91debeeb42">rounding_policy</a>;         <span class="comment">/*!&lt; \brief A &lt;tt&gt; VX_TYPE_ENUM&lt;/tt&gt; of the &lt;tt&gt; vx_round_policy_e&lt;/tt&gt; enumeration. */</span></div><div class="line"><a name="l00186"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#a5296a774c77309f9f9ead807445be56f">  186</a></span>&#160;    vx_enum <a class="code" href="../../d6/d9a/group__group__cnn.html#a5296a774c77309f9f9ead807445be56f">down_scale_size_rounding</a>; <span class="comment">/*!&lt; \brief Rounding method for calculating output dimensions. See &lt;tt&gt;\ref vx_nn_rounding_type_e&lt;/tt&gt; */</span></div><div class="line"><a name="l00187"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#a713d31f84f4d45780b6f8f7236c4f456">  187</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#a713d31f84f4d45780b6f8f7236c4f456">dilation_x</a>;            <span class="comment">/*!&lt; \brief “inflate” the kernel by inserting zeros between the kernel elements in the x direction. The value is the number of zeros to insert.*/</span></div><div class="line"><a name="l00188"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#a455f16c8987d05355d77ceb22c2e9dd6">  188</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#a455f16c8987d05355d77ceb22c2e9dd6">dilation_y</a>;            <span class="comment">/*!&lt; \brief “inflate” the kernel by inserting zeros between the kernel elements in the y direction. The value is the number of zeros to insert.*/</span></div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;} <a class="code" href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a>;</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;<span class="comment">/*! \brief Input parameters for a deconvolution operation.</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00195"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html">  195</a></span>&#160;<span class="keyword">typedef</span> <span class="keyword">struct </span>_vx_nn_deconvolution_params_t</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;{</div><div class="line"><a name="l00197"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#aaa9dcb4ba92e41fcd8098f466a7a888e">  197</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#aaa9dcb4ba92e41fcd8098f466a7a888e">padding_x</a>;                 <span class="comment">/*!&lt; \brief Number of elements subtracted at each side in the x dimension of the output. */</span></div><div class="line"><a name="l00198"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ad55be69baba9c172496b79a9756a7115">  198</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#ad55be69baba9c172496b79a9756a7115">padding_y</a>;                 <span class="comment">/*!&lt; \brief Number of elements subtracted at each side in the y dimension of the output. */</span></div><div class="line"><a name="l00199"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#a454f2e9685c4efb4c2437ebef44602b4">  199</a></span>&#160;    vx_enum <a class="code" href="../../d6/d9a/group__group__cnn.html#a454f2e9685c4efb4c2437ebef44602b4">overflow_policy</a>;         <span class="comment">/*!&lt; \brief A &lt;tt&gt; VX_TYPE_ENUM&lt;/tt&gt; of the &lt;tt&gt; vx_convert_policy_e&lt;/tt&gt; enumeration. */</span></div><div class="line"><a name="l00200"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#af5f8d839a7182f7d1890b2469df5a07c">  200</a></span>&#160;    vx_enum <a class="code" href="../../d6/d9a/group__group__cnn.html#af5f8d839a7182f7d1890b2469df5a07c">rounding_policy</a>;         <span class="comment">/*!&lt; \brief A &lt;tt&gt; VX_TYPE_ENUM&lt;/tt&gt; of the &lt;tt&gt; vx_round_policy_e&lt;/tt&gt; enumeration. */</span></div><div class="line"><a name="l00201"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#a154d04fd1c8f67a4b98f7b4aa7460ccb">  201</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#a154d04fd1c8f67a4b98f7b4aa7460ccb">a_x</a>;                 <span class="comment">/*!&lt; \brief user-specified quantity used to distinguish between the \f$upscale_x\f$ different possible output sizes. */</span></div><div class="line"><a name="l00202"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#aaa91b1e661cbcb791ee28274d220e85b">  202</a></span>&#160;    vx_size <a class="code" href="../../d6/d9a/group__group__cnn.html#aaa91b1e661cbcb791ee28274d220e85b">a_y</a>;                 <span class="comment">/*!&lt; \brief user-specified quantity used to distinguish between the \f$upscale_y\f$ different possible output sizes. */</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;} <a class="code" href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a>;</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="comment">/*! \brief Input parameters for ROI pooling operation.</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00208"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html">  208</a></span>&#160;<span class="keyword">typedef</span> <span class="keyword">struct </span>_vx_nn_roi_pool_params_t</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;{</div><div class="line"><a name="l00210"></a><span class="lineno"><a class="line" href="../../d6/d9a/group__group__cnn.html#ad8cb5ae660ac3040ea8fb2f965ed3c75">  210</a></span>&#160;    vx_enum <a class="code" href="../../d6/d9a/group__group__cnn.html#ad8cb5ae660ac3040ea8fb2f965ed3c75">pool_type</a>;  <span class="comment">/*!&lt; \brief Of type &lt;tt&gt;\ref vx_nn_pooling_type_e&lt;/tt&gt;. Only &lt;tt&gt;\ref VX_NN_POOLING_MAX&lt;/tt&gt; pooling is supported. */</span></div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;} <a class="code" href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">vx_nn_roi_pool_params_t</a>;</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;<span class="comment">/*==============================================================================</span></div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;<span class="comment">    NN Nodes</span></div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="comment">=============================================================================*/</span><span class="comment"></span></div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Convolutional Network Convolution Layer Node.</span></div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment"> * \details This function implement Convolutional Network Convolution layer.</span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;<span class="comment"> *  For fixed-point data types, a fixed point calculation is performed with round and saturate according to the number of accumulator bits. The number of the accumulator bits are implementation defined,</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="comment"> * and should be at least 16.\n</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="comment"> * round: rounding according the &lt;tt&gt;vx_round_policy_e&lt;/tt&gt; enumeration. \n</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="comment"> * saturate: A saturation according the &lt;tt&gt;vx_convert_policy_e&lt;/tt&gt; enumeration.</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="comment"> * The following equation is implemented: \n</span></div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;<span class="comment"> * \f$ outputs[j,k,i] = saturate(round(\sum_{l} (\sum_{m,n} inputs[j+m,k+n,l] \times weights[m,n,l,i])+biasses[j,k,i])) \f$\n</span></div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;<span class="comment"> * Where \f$m,n\f$ are indexes on the convolution matrices. \f$ l\f$ is an index on all the convolutions per input.\f$ i\f$ is an index per output.</span></div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;<span class="comment"> * \f$ j,k \f$ are the inputs/outputs spatial indexes.</span></div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;<span class="comment"> * Convolution is done on the width and height dimensions of the &lt;tt&gt;\ref vx_tensor&lt;/tt&gt;. Therefore, we use here the term x for index along the width dimension and y for index along the height dimension.\n</span></div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;<span class="comment"> * before the Convolution is done, a padding with zeros of the width and height input dimensions is performed.</span></div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="comment"> * Then down scale is done by picking the results according to a skip jump. The skip in the x and y is determined by the output size dimensions.</span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;<span class="comment"> * The relation between input to output is as follows: \n</span></div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="comment"> * \f$ width_{output} = round(\frac{(width_{input} + 2 * padding_x - kernel_x - (kernel_x -1) * dilation_x)}{skip_x} + 1) \f$\n</span></div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;<span class="comment"> * and \n</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment"> * \f$ height_{output} = round(\frac{(height + 2 * padding_y - kernel_y - (kernel_y -1) * dilation_y)}{skip_y} + 1) \f$\n </span></div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;<span class="comment"> * where \f$width\f$ is the size of the input width dimension. \f$height\f$ is the size of the input height dimension.</span></div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;<span class="comment"> * \f$width_{output}\f$ is the size of the output width dimension. \f$height_{output}\f$ is the size of the output height dimension.</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;<span class="comment"> * \f$kernel_x\f$ and \f$kernel_y\f$ are the convolution sizes in width and height dimensions.</span></div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="comment"> * skip is calculated by the relation between input and output. In case of ambiguity in the inverse calculation of the skip. The minimum solution is chosen. Skip must be a positive non zero integer.</span></div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="comment"> * rounding is done according to &lt;tt&gt;\ref vx_nn_rounding_type_e&lt;/tt&gt;.</span></div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment"> * Notice that this node creation function has more parameters than the corresponding kernel. Numbering of kernel parameters (required if you create this node using the generic interface) is explicitly specified here.</span></div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;<span class="comment"> * \param [in] inputs The input tensor data. 3 lower dimensions represent a single input, all following dimensions represent number of batches, possibly nested.</span></div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;<span class="comment"> * The dimension order is [width, height, #IFM, #batches]\n. Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8&#39; or &#39;KHR_NN_8 KHR_NN_16&#39;.  (Kernel parameter #0)</span></div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;<span class="comment"> * \param [in] weights [static] Weights are 4d tensor with dimensions [kernel_x, kernel_y, #IFM, #OFM]. see &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt; \n Weights data type must match the data type of the inputs.  (Kernel parameter #1)</span></div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;<span class="comment"> * \param [in] biases [static] Optional, ignored if NULL. The biases, which may be shared (one per ofm) or unshared (one per ofm * output location). The possible layouts are</span></div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;<span class="comment"> * either [#OFM] or [width, height, #OFM]. Biases data type must match the data type of the inputs.   (Kernel parameter #2)</span></div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;<span class="comment"> * \param [in] convolution_params [static] Pointer to parameters of type &lt;tt&gt;\ref vx_nn_convolution_params_t&lt;/tt&gt;.  (Kernel parameter #3)</span></div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;<span class="comment"> * \param [in] size_of_convolution_params [static] Size in bytes of convolution_params. Note that this parameter is not counted as one of the kernel parameters.</span></div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;<span class="comment"> * \param [out] outputs The output tensor data. Output will have the same number and structure of dimensions as input. Output tensor data type must be same as the inputs.  (Kernel parameter #4)</span></div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;VX_API_ENTRY vx_node VX_API_CALL <a class="code" href="../../d6/d9a/group__group__cnn.html#ga69764625f436c14d739fc467515c1584">vxConvolutionLayer</a>(vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, <span class="keyword">const</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a> *convolution_params, vx_size size_of_convolution_params, vx_tensor outputs);</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Fully connected Convolutional Network Layer Node.</span></div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;<span class="comment"> * \details This function implement Fully connected Convolutional Network layers.</span></div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="comment"> * For fixed-point data types, a fixed point calculation is performed with round and saturate according to the number of accumulator bits. The number of the accumulator bits are implementation defined,</span></div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;<span class="comment"> * and should be at least 16.\n</span></div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;<span class="comment"> * round: rounding according the &lt;tt&gt;vx_round_policy_e&lt;/tt&gt; enumeration. \n</span></div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;<span class="comment"> * saturate: A saturation according the &lt;tt&gt;vx_convert_policy_e&lt;/tt&gt; enumeration.</span></div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;<span class="comment"> * The equation for Fully connected layer:\n</span></div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;<span class="comment"> * \f$ outputs[i] = saturate(round(\sum_{j} (inputs[j] \times weights[j,i])+biasses[i])) \f$\n</span></div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;<span class="comment"> * Where \f$j\f$ is a index on the input feature and \f$i\f$ is a index on the output.</span></div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;<span class="comment"> * \param [in] inputs The input tensor data. There two possible input layouts:</span></div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;<span class="comment"> * 1. [#IFM, #batches]. See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;.</span></div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;<span class="comment"> * 2. [width, height, #IFM, #batches]. See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;\n</span></div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;<span class="comment"> * In both cases number of batches are optional and may be multidimensional.</span></div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;<span class="comment"> * The second option is a special case to deal with convolution layer followed by fully connected.</span></div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;<span class="comment"> * The dimension order is [#IFM, #batches]. See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;. Note that batch may be multidimensional. Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8&#39; or &#39;KHR_NN_8 KHR_NN_16&#39;. </span></div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;<span class="comment"> * \param [in] weights [static] Number of dimensions is 2. Dimensions are [#IFM, #OFM]. See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;.\n Implementations must support input tensor data type same as the inputs.</span></div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;<span class="comment"> * \param [in] biases [static] Optional, ignored if NULL. The biases have one dimension [#OFM]. Implementations must support input tensor data type same as the inputs.</span></div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;<span class="comment"> * \param [in] overflow_policy [static] A &lt;tt&gt; VX_TYPE_ENUM&lt;/tt&gt; of the &lt;tt&gt; vx_convert_policy_e&lt;/tt&gt; enumeration.</span></div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;<span class="comment"> * \param [in] rounding_policy [static] A &lt;tt&gt; VX_TYPE_ENUM&lt;/tt&gt; of the &lt;tt&gt; vx_round_policy_e&lt;/tt&gt; enumeration.</span></div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;<span class="comment"> * \param [out] outputs The output tensor data. Output dimension layout is [#OFM,#batches]. See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;, where #batches may be multidimensional. Output tensor data type must be same as the inputs.</span></div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;VX_API_ENTRY vx_node VX_API_CALL <a class="code" href="../../d6/d9a/group__group__cnn.html#ga70f11e4a18658dd8753f9d8e009730b2">vxFullyConnectedLayer</a>(vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, vx_enum overflow_policy, vx_enum rounding_policy, vx_tensor outputs);</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Convolutional Network Pooling Layer Node.</span></div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;<span class="comment"> * \details Pooling is done on the width and height dimensions of the &lt;tt&gt;\ref vx_tensor&lt;/tt&gt;. Therefore, we use here the term x for the width dimension and y for the height dimension.\n</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;<span class="comment"> * Pooling operation is a function operation over a rectangle size and then a nearest neighbour down scale.</span></div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;<span class="comment"> * Here we use pooling_size_x and pooling_size_y to specify the rectangle size on which the operation</span></div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;<span class="comment"> * is performed. \n</span></div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;<span class="comment"> * before the operation is done (average or maximum value). the data is padded with zeros in width and height dimensions .</span></div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;<span class="comment"> * The down scale is done by picking the results according to a skip jump. The skip in the x and y dimension is determined by the output size dimensions.</span></div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;<span class="comment"> * The first pixel of the down scale output is the first pixel in the input.</span></div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;<span class="comment"> * \param [in] inputs The input tensor data. 3 lower dimensions represent a single input, 4th dimension for batch of inputs is optional.Dimension layout is [width, height, #IFM, #batches].</span></div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;<span class="comment"> * See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt; </span></div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;<span class="comment"> * Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8&#39; or &#39;KHR_NN_8 KHR_NN_16&#39;. </span></div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;<span class="comment"> * \param [in] pooling_type [static] Either max pooling or average pooling (see &lt;tt&gt;\ref vx_nn_pooling_type_e&lt;/tt&gt;).</span></div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="comment"> * \param [in] pooling_size_x [static] Size of the pooling region in the x dimension</span></div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;<span class="comment"> * \param [in] pooling_size_y [static] Size of the pooling region in the y dimension.</span></div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;<span class="comment"> * \param [in] pooling_padding_x [static] Padding size in the x dimension.</span></div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;<span class="comment"> * \param [in] pooling_padding_y [static] Padding size in the y dimension.</span></div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="comment"> * \param [in] rounding [static] Rounding method for calculating output dimensions. See &lt;tt&gt;\ref vx_nn_rounding_type_e&lt;/tt&gt;</span></div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="comment"> * \param [out] outputs The output tensor data. Output will have the same number of dimensions as input. Output tensor data type must be same as the inputs.</span></div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;VX_API_ENTRY vx_node VX_API_CALL <a class="code" href="../../d6/d9a/group__group__cnn.html#gac4e286be0f9c9a2fbd3019fd74531332">vxPoolingLayer</a>(vx_graph graph, vx_tensor inputs, vx_enum pooling_type,</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;        vx_size pooling_size_x,</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;        vx_size pooling_size_y,</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;        vx_size pooling_padding_x,</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;        vx_size pooling_padding_y,</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;        vx_enum rounding, </div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;        vx_tensor outputs);</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Convolutional Network Softmax Layer Node.</span></div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;<span class="comment"> * \details  the softmax function, is a generalization of the logistic function that &quot;squashes&quot; a K-dimensional vector \f$ z \f$ of arbitrary real values to a K-dimensional vector</span></div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;<span class="comment"> * \f$ \sigma(z) \f$ of real values in the range (0, 1) that add up to 1. The function is given by:</span></div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;<span class="comment"> * \f$ \sigma(z) = \frac{\exp^z}{\sum_i \exp^{z_i}} \f$</span></div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;<span class="comment"> * \param [in] inputs The input tensor,  with the number of dimensions according to the following scheme. </span></div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;<span class="comment"> * In case IFM dimension is 1. Softmax is be calculated on that dimension.</span></div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;<span class="comment"> * In case IFM dimension is 2. Softmax is be calculated on the first dimension. The second dimension is batching.</span></div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;<span class="comment"> * In case IFM dimension is 3. Dimensions are [Width, Height, Classes]. And Softmax is calculated on the third dimension.</span></div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;<span class="comment"> * In case IFM dimension is 4. Dimensions are [Width, Height, Classes, batching]. Softmax is calculated on the third dimension.</span></div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;<span class="comment"> * Regarding the layout specification, see &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;.</span></div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;<span class="comment"> * In all cases Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8&#39; or &#39;KHR_NN_8 KHR_NN_16&#39;. </span></div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;<span class="comment"> * \param [out] outputs The output tensor. Output will have the same number of dimensions as input. Output tensor data type must be same as the inputs.</span></div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;VX_API_ENTRY vx_node VX_API_CALL <a class="code" href="../../d6/d9a/group__group__cnn.html#ga76a3a94a73992017519d7dc01e81c476">vxSoftmaxLayer</a>(vx_graph graph, vx_tensor inputs, vx_tensor outputs);</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Convolutional Network Normalization Layer Node. This function is optional for 8-bit extension with the extension string &#39;KHR_NN_8&#39;. </span></div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;<span class="comment"> * \details Normalizing over local input regions. Each input value is divided by \f$ (1+\frac{\alpha}{n}\sum_i x^2_i)^\beta \f$ , where n is the number of elements to normalize across.</span></div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;<span class="comment"> * and the sum is taken over a rectangle region centred at that value (zero padding is added where necessary).</span></div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="comment"> * \param [in] inputs The input tensor data. 3 lower dimensions represent a single input, 4th dimension for batch of inputs is optional.Dimension layout is [width, height, IFM, #batches].</span></div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;<span class="comment"> * See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;.</span></div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;<span class="comment"> * Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8 KHR_NN_16&#39;. </span></div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;<span class="comment"> * Since this function is optional for &#39;KHR_NN_8&#39;, so implementations only must support &lt;tt&gt;VX_TYPE_INT16&lt;/tt&gt; with fixed_point_position 8.</span></div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;<span class="comment"> * \param [in] type [static] Either same map or across maps (see &lt;tt&gt;\ref vx_nn_norm_type_e&lt;/tt&gt;).</span></div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;<span class="comment"> * \param [in] normalization_size [static] Number of elements to normalize across. Must be a positive odd number with maximum size of 7 and minimum of 3.</span></div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;<span class="comment"> * \param [in] alpha [static] Alpha parameter in the normalization equation. must be positive.</span></div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;<span class="comment"> * \param [in] beta  [static] Beta parameter in the normalization equation. must be positive.</span></div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;<span class="comment"> * \param [out] outputs The output tensor data. Output will have the same number of dimensions as input.</span></div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;VX_API_ENTRY vx_node VX_API_CALL <a class="code" href="../../d6/d9a/group__group__cnn.html#ga2f2dd3b8c00370e78552ef64bb2a174c">vxNormalizationLayer</a>(vx_graph graph, vx_tensor inputs, vx_enum type,</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;        vx_size normalization_size,</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;        vx_float32 alpha,</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;        vx_float32 beta,</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;        vx_tensor outputs);</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Convolutional Network Activation Layer Node.</span></div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;<span class="comment"> * The function operate a specific function (Specified in &lt;tt&gt;\ref vx_nn_activation_function_e&lt;/tt&gt;), On the input data.</span></div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;<span class="comment"> * the equation for the layer is:</span></div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;<span class="comment"> * \f$ outputs(i,j,k,l) = function(inputs(i,j,k,l), a, b) \f$ for all i,j,k,l.</span></div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;<span class="comment"> * \param [in] inputs The input tensor data.</span></div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;<span class="comment"> * Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8&#39; or &#39;KHR_NN_8 KHR_NN_16&#39;. </span></div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;<span class="comment"> * \param [in] function [static] Non-linear function (see &lt;tt&gt;\ref vx_nn_activation_function_e&lt;/tt&gt;). Implementations must support &lt;tt&gt;\ref VX_NN_ACTIVATION_LOGISTIC&lt;/tt&gt;, &lt;tt&gt;\ref VX_NN_ACTIVATION_HYPERBOLIC_TAN&lt;/tt&gt; and &lt;tt&gt;\ref VX_NN_ACTIVATION_RELU&lt;/tt&gt;</span></div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;<span class="comment"> * \param [in] a [static] Function parameters a. must be positive.</span></div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;<span class="comment"> * \param [in] b [static] Function parameters b. must be positive.</span></div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;<span class="comment"> * \param [out] outputs The output tensor data. Output will have the same number of dimensions as input.</span></div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;VX_API_ENTRY vx_node VX_API_CALL <a class="code" href="../../d6/d9a/group__group__cnn.html#ga81fccaa902dfe507dace415f189d5e5e">vxActivationLayer</a>(vx_graph graph, vx_tensor inputs, vx_enum <span class="keyword">function</span>, vx_float32 a,vx_float32 b, vx_tensor outputs); </div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Convolutional Network ROI pooling node</span></div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;<span class="comment"> * \details Pooling is done on the width and height dimensions of the &lt;tt&gt;\ref vx_tensor&lt;/tt&gt;. The ROI Pooling get an array of roi rectangles, and an input tensor.</span></div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;<span class="comment"> * The kernel crop the width and height dimensions of the input tensor with the ROI rectangles and down scale the result to the size of the output tensor. The output tensor width and height are the pooled width and pooled height.</span></div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;<span class="comment"> * The down scale method is determined by the pool_type.</span></div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;<span class="comment"> * Notice that this node creation function has more parameters than the corresponding kernel. Numbering of kernel parameters (required if you create this node using the generic interface) is explicitly specified here.</span></div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;<span class="comment"> * \param [in] inputs The input tensor data. 3 lower dimensions represent a single input, 4th dimension for batch of inputs is optional. Dimension layout is [width, height, #IFM, #batches]. </span></div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;<span class="comment"> * See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;.</span></div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;<span class="comment"> * Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8&#39; or &#39;KHR_NN_8 KHR_NN_16&#39;.  (Kernel parameter #0) </span></div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;<span class="comment"> * \param [in] inputs_rois The roi array tensor. ROI array with dimensions [4, roi_count, #batches] where the first dimension represents 4 coordinates of the top left and bottom right corners of the roi rectangles, based on the input tensor width and height.</span></div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;<span class="comment"> * #batches is optional and must be the same as in inputs. roi_count is the number of ROI rectangles.  (Kernel parameter #1)</span></div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;<span class="comment"> * \param [in] pool_type [static] Of type &lt;tt&gt;\ref vx_nn_pooling_type_e&lt;/tt&gt;. Only &lt;tt&gt;\ref VX_NN_POOLING_MAX&lt;/tt&gt; pooling is supported.   (Kernel parameter #2)</span></div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;<span class="comment"> * \param [in] size_of_roi_params [static] Size in bytes of roi_pool_params. Note that this parameter is not counted as one of the kernel parameters.</span></div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;<span class="comment"> * \param [out] output_arr The output tensor. Output will have [output_width, output_height, #IFM, #batches] dimensions. #batches is optional and must be the same as in inputs.  (Kernel parameter #3)</span></div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;VX_API_ENTRY vx_node <a class="code" href="../../d6/d9a/group__group__cnn.html#gae80cce7ad61e5b4ac9e1c1136f40d65e">vxROIPoolingLayer</a>(vx_graph graph, vx_tensor input_data, vx_tensor input_rois, <span class="keyword">const</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">vx_nn_roi_pool_params_t</a> *roi_pool_params, vx_size size_of_roi_params, vx_tensor output_arr);</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;                </div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;                <span class="comment"></span></div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;<span class="comment">/*! \brief [Graph] Creates a Convolutional Network Deconvolution Layer Node.</span></div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;<span class="comment"> * \details  Deconvolution denote a sort of reverse convolution, which importantly and confusingly is not actually a proper mathematical deconvolution.</span></div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;<span class="comment"> * Convolutional Network Deconvolution is up-sampling of an image by learned Deconvolution coefficients.</span></div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;<span class="comment"> * The operation is similar to convolution but can be implemented by up-sampling the inputs with zeros insertions between the inputs,</span></div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;<span class="comment"> * and convolving the Deconvolution kernels on the up-sampled result. </span></div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;<span class="comment"> * For fixed-point data types, a fixed point calculation is performed with round and saturate according to the number of accumulator bits. The number of the accumulator bits are implementation defined,</span></div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;<span class="comment"> * and should be at least 16.\n</span></div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;<span class="comment"> * round: rounding according the &lt;tt&gt;vx_round_policy_e&lt;/tt&gt; enumeration. \n</span></div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;<span class="comment"> * saturate: A saturation according the &lt;tt&gt;vx_convert_policy_e&lt;/tt&gt; enumeration.</span></div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;<span class="comment"> * The following equation is implemented: \n</span></div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;<span class="comment"> * \f$ outputs[j,k,i] =  saturate(round(\sum_{l} \sum_{m,n}(inputs_{upscaled}[j+m,k+n,l] \times weights[m,n,l,i])+biasses[j,k,i])) \f$\n</span></div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;<span class="comment"> * Where \f$m,n\f$ are indexes on the convolution matrices. \f$ l\f$ is an index on all the convolutions per input.\f$ i\f$ is an index per output.</span></div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;<span class="comment"> * \f$ j,k \f$ are the inputs/outputs spatial indexes.</span></div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;<span class="comment"> * Deconvolution is done on the width and height dimensions of the &lt;tt&gt;\ref vx_tensor&lt;/tt&gt;. Therefore, we use here the term x for the width dimension and y for the height dimension.\n</span></div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;<span class="comment"> * before the Deconvolution is done, up-scaling the width and height dimensions with zeros is performed.</span></div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;<span class="comment"> * The relation between input to output is as follows: \n</span></div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;<span class="comment"> * \f$ width_{output} =  (width_{input} -1) * upscale_x  - 2 * padding_x + kernel_x + a_x \f$\n</span></div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;<span class="comment"> * and \n</span></div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;<span class="comment"> * \f$ height_{output} =  (height_{input} - 1) * upscale_y - 2 * padding_y + kernel_y + a_y \f$\n </span></div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;<span class="comment"> * where \f$width_{input}\f$ is the size of the input width dimension. \f$height_{input}\f$ is the size of the input height dimension.</span></div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;<span class="comment"> * \f$width_{output}\f$ is the size of the output width dimension. \f$height_{output}\f$ is the size of the output height dimension.</span></div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;<span class="comment"> * \f$kernel_x\f$ and \f$kernel_y\f$ are the convolution sizes in width and height. \f$a_x\f$ and \f$a_y\f$ are user-specified quantity used to distinguish between the \f$upscale_x\f$ and \f$upscale_y\f$ different possible output sizes.</span></div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="comment"> * \f$upscale_x\f$ and \f$upscale_y\f$ are calculated by the relation between input and output.</span></div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;<span class="comment"> * \f$a_x\f$ and \f$a_y\f$ must be positive and smaller then \f$upscale_x\f$ and \f$upscale_y\f$ respectively.</span></div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;<span class="comment"> * Since the padding parameter is on the output. The effective input padding is: \n</span></div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment"> * \f$ padding_{input_x} = kernel_x -padding_x -1\f$ \n</span></div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;<span class="comment"> * \f$ padding_{input_y} = kernel_y -padding_y -1\f$ \n</span></div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;<span class="comment"> * Therfore the following constarints apply : \f$kernel_x &gt;= padding_x - 1\f$ and \f$kernel_y &gt;= padding_y - 1\f$.</span></div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;<span class="comment"> * rounding is done according to &lt;tt&gt;\ref vx_nn_rounding_type_e&lt;/tt&gt;.</span></div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;<span class="comment"> * Notice that this node creation function has more parameters than the corresponding kernel. Numbering of kernel parameters (required if you create this node using the generic interface) is explicitly specified here.</span></div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;<span class="comment"> * \param [in] graph The handle to the graph.</span></div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;<span class="comment"> * \param [in] inputs The input tensor. 3 lower dimensions represent a single input, and an optional 4th dimension for batch of inputs. Dimension layout is [width, height, #IFM, #batches].</span></div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;<span class="comment"> * See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;.</span></div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;<span class="comment"> * Implementations must support input tensor data types indicated by the extension strings &#39;KHR_NN_8&#39; or &#39;KHR_NN_8 KHR_NN_16&#39;.   (Kernel parameter #0)</span></div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;<span class="comment"> * \param [in] weights [static] The 4d weights with dimensions [width, height, #IFM, #OFM]. See &lt;tt&gt;\ref vxCreateTensor&lt;/tt&gt; and &lt;tt&gt;\ref vxCreateVirtualTensor&lt;/tt&gt;.  (Kernel parameter #1)</span></div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;<span class="comment"> * \param [in] biases [static] Optional, ignored if NULL. The biases have one dimension [#OFM]. Implementations must support input tensor data type same as the inputs.  (Kernel parameter #2)</span></div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;<span class="comment"> * \param [in] deconvolution_params [static] Pointer to parameters of type &lt;tt&gt;\ref vx_nn_deconvolution_params_t&lt;/tt&gt;  (Kernel parameter #3)</span></div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;<span class="comment"> * \param [in] size_of_deconv_params [static] Size in bytes of deconvolution_params. Note that this parameter is not counted as one of the kernel parameters.</span></div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;<span class="comment"> * \param [out] outputs The output tensor. The output has the same number of dimensions as the input.  (Kernel parameter #4)</span></div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;<span class="comment"> * \ingroup group_cnn</span></div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;<span class="comment"> * \return &lt;tt&gt; vx_node&lt;/tt&gt;.</span></div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;<span class="comment"> * \returns A node reference &lt;tt&gt;\ref vx_node&lt;/tt&gt;. Any possible errors preventing a</span></div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;<span class="comment"> * successful creation should be checked using &lt;tt&gt;\ref vxGetStatus&lt;/tt&gt;.</span></div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;VX_API_ENTRY vx_node VX_API_CALL <a class="code" href="../../d6/d9a/group__group__cnn.html#ga5c056442529c4c979eb6b82d81cab907">vxDeconvolutionLayer</a>(vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor  biases, <span class="keyword">const</span> <a class="code" href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a> *deconvolution_params, vx_size size_of_deconv_params, vx_tensor outputs);</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;<span class="preprocessor">#ifdef  __cplusplus</span></div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;}</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;</div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efad75b4eaef510d969e412aa08d2cb3edc"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efad75b4eaef510d969e412aa08d2cb3edc">VX_KERNEL_POOLING_LAYER</a></div><div class="ttdoc">The Neural Network Extension pooling Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00063">vx_khr_nn.h:63</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga76a3a94a73992017519d7dc01e81c476"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga76a3a94a73992017519d7dc01e81c476">vxSoftmaxLayer</a></div><div class="ttdeci">vx_node vxSoftmaxLayer(vx_graph graph, vx_tensor inputs, vx_tensor outputs)</div><div class="ttdoc">[Graph] Creates a Convolutional Network Softmax Layer Node. </div></div>
<div class="ttc" id="group__group__cnn_html_ad8cb5ae660ac3040ea8fb2f965ed3c75"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ad8cb5ae660ac3040ea8fb2f965ed3c75">vx_nn_roi_pool_params_t::pool_type</a></div><div class="ttdeci">vx_enum pool_type</div><div class="ttdoc">Of type vx_nn_pooling_type_e. Only VX_NN_POOLING_MAX pooling is supported. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00210">vx_khr_nn.h:210</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga27a8a65bf3129353d6446474b0b78164af06282ca200b459a31d85e09aec81cc1"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164af06282ca200b459a31d85e09aec81cc1">VX_TYPE_NN_ROI_POOL_PARAMS</a></div><div class="ttdoc">A vx_nn_roi_pool_params_t. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00174">vx_khr_nn.h:174</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga70f11e4a18658dd8753f9d8e009730b2"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga70f11e4a18658dd8753f9d8e009730b2">vxFullyConnectedLayer</a></div><div class="ttdeci">vx_node vxFullyConnectedLayer(vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, vx_enum overflow_policy, vx_enum rounding_policy, vx_tensor outputs)</div><div class="ttdoc">[Graph] Creates a Fully connected Convolutional Network Layer Node. </div></div>
<div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efafcfbeeb8d83b4ae949ec8fd06c7dcc19"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efafcfbeeb8d83b4ae949ec8fd06c7dcc19">VX_KERNEL_ACTIVATION_LAYER</a></div><div class="ttdoc">The Neural Network Extension activation Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00075">vx_khr_nn.h:75</a></div></div>
<div class="ttc" id="group__group__cnn_html_gad499c32ff42607fcffda9c3cca7185ef"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gad499c32ff42607fcffda9c3cca7185ef">vx_kernel_nn_ext_e</a></div><div class="ttdeci">vx_kernel_nn_ext_e</div><div class="ttdoc">The list of Neural Network Extension Kernels. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00051">vx_khr_nn.h:51</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga86bbe62218962d22af01d434a42603c6"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a></div><div class="ttdeci">vx_nn_rounding_type_e</div><div class="ttdoc">down scale rounding. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00103">vx_khr_nn.h:103</a></div></div>
<div class="ttc" id="group__group__cnn_html_gae5b5a30ecdff611b248b26f65d7aa900"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gae5b5a30ecdff611b248b26f65d7aa900">vx_nn_enum_e</a></div><div class="ttdeci">vx_nn_enum_e</div><div class="ttdoc">NN extension type enums. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00089">vx_khr_nn.h:89</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga86bbe62218962d22af01d434a42603c6a2aa48ad506133fdf01c0bd37f6293860"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6a2aa48ad506133fdf01c0bd37f6293860">VX_NN_DS_SIZE_ROUNDING_FLOOR</a></div><div class="ttdoc">floor rounding </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00106">vx_khr_nn.h:106</a></div></div>
<div class="ttc" id="group__group__cnn_html_a154d04fd1c8f67a4b98f7b4aa7460ccb"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#a154d04fd1c8f67a4b98f7b4aa7460ccb">vx_nn_deconvolution_params_t::a_x</a></div><div class="ttdeci">vx_size a_x</div><div class="ttdoc">user-specified quantity used to distinguish between the  different possible output sizes...</div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00201">vx_khr_nn.h:201</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga81fccaa902dfe507dace415f189d5e5e"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga81fccaa902dfe507dace415f189d5e5e">vxActivationLayer</a></div><div class="ttdeci">vx_node vxActivationLayer(vx_graph graph, vx_tensor inputs, vx_enum function, vx_float32 a, vx_float32 b, vx_tensor outputs)</div><div class="ttdoc">[Graph] Creates a Convolutional Network Activation Layer Node. The function operate a specific functi...</div></div>
<div class="ttc" id="group__group__cnn_html_ga516b0d3e8da43e82826bcccfc196c3e2"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">vx_nn_pooling_type_e</a></div><div class="ttdeci">vx_nn_pooling_type_e</div><div class="ttdoc">The Neural Network pooling type list. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00116">vx_khr_nn.h:116</a></div></div>
<div class="ttc" id="group__group__cnn_html_gae80cce7ad61e5b4ac9e1c1136f40d65e"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gae80cce7ad61e5b4ac9e1c1136f40d65e">vxROIPoolingLayer</a></div><div class="ttdeci">vx_node vxROIPoolingLayer(vx_graph graph, vx_tensor input_data, vx_tensor input_rois, vx_nn_roi_pool_params_t *roi_pool_params, vx_size size_of_roi_params, vx_tensor output_arr)</div><div class="ttdoc">[Graph] Creates a Convolutional Network ROI pooling node </div></div>
<div class="ttc" id="group__group__cnn_html_ga5c056442529c4c979eb6b82d81cab907"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga5c056442529c4c979eb6b82d81cab907">vxDeconvolutionLayer</a></div><div class="ttdeci">vx_node vxDeconvolutionLayer(vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, vx_nn_deconvolution_params_t *deconvolution_params, vx_size size_of_deconv_params, vx_tensor outputs)</div><div class="ttdoc">[Graph] Creates a Convolutional Network Deconvolution Layer Node. </div></div>
<div class="ttc" id="group__group__cnn_html_a455f16c8987d05355d77ceb22c2e9dd6"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#a455f16c8987d05355d77ceb22c2e9dd6">vx_nn_convolution_params_t::dilation_y</a></div><div class="ttdeci">vx_size dilation_y</div><div class="ttdoc">“inflate” the kernel by inserting zeros between the kernel elements in the y direction. The value is the number of zeros to insert. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00188">vx_khr_nn.h:188</a></div></div>
<div class="ttc" id="group__group__cnn_html_a5fb7b1019861afc6098197139bc991bc"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#a5fb7b1019861afc6098197139bc991bc">vx_nn_convolution_params_t::overflow_policy</a></div><div class="ttdeci">vx_enum overflow_policy</div><div class="ttdoc">A  VX_TYPE_ENUM of the  vx_convert_policy_e enumeration. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00184">vx_khr_nn.h:184</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc">VX_NN_POOLING_MAX</a></div><div class="ttdoc">max pooling </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00119">vx_khr_nn.h:119</a></div></div>
<div class="ttc" id="group__group__cnn_html_af5f8d839a7182f7d1890b2469df5a07c"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#af5f8d839a7182f7d1890b2469df5a07c">vx_nn_deconvolution_params_t::rounding_policy</a></div><div class="ttdeci">vx_enum rounding_policy</div><div class="ttdoc">A  VX_TYPE_ENUM of the  vx_round_policy_e enumeration. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00200">vx_khr_nn.h:200</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga516b0d3e8da43e82826bcccfc196c3e2add52234a10e4685d1958be373319741c"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2add52234a10e4685d1958be373319741c">VX_NN_POOLING_AVG</a></div><div class="ttdoc">average pooling </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00121">vx_khr_nn.h:121</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga5edc475524c86e326b56ffaa7e8eaa28a9cb28001c736aa33d54a839e812a40ed"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28a9cb28001c736aa33d54a839e812a40ed">VX_NN_NORMALIZATION_ACROSS_MAPS</a></div><div class="ttdoc">Normalization is done across different IFMs. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00133">vx_khr_nn.h:133</a></div></div>
<div class="ttc" id="group__group__cnn_html_a454f2e9685c4efb4c2437ebef44602b4"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#a454f2e9685c4efb4c2437ebef44602b4">vx_nn_deconvolution_params_t::overflow_policy</a></div><div class="ttdeci">vx_enum overflow_policy</div><div class="ttdoc">A  VX_TYPE_ENUM of the  vx_convert_policy_e enumeration. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00199">vx_khr_nn.h:199</a></div></div>
<div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efa0993f051aa373134ea832496168d6fed"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa0993f051aa373134ea832496168d6fed">VX_KERNEL_DECONVOLUTION_LAYER</a></div><div class="ttdoc">The Neural Network Extension Deconvolution Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00083">vx_khr_nn.h:83</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga27a8a65bf3129353d6446474b0b78164a411116ea30558ddbf45dc7db2074522f"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a411116ea30558ddbf45dc7db2074522f">VX_TYPE_NN_CONVOLUTION_PARAMS</a></div><div class="ttdoc">A vx_nn_convolution_params_t. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00172">vx_khr_nn.h:172</a></div></div>
<div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efa04b0137b6e503e303c75f38da895cfe9"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa04b0137b6e503e303c75f38da895cfe9">VX_KERNEL_ROI_POOLING_LAYER</a></div><div class="ttdoc">The Neural Network POI Pooling Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00079">vx_khr_nn.h:79</a></div></div>
<div class="ttc" id="group__group__cnn_html_ac420cbc3cb68cc9786c4050892df95a4"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ac420cbc3cb68cc9786c4050892df95a4">vx_nn_convolution_params_t::padding_y</a></div><div class="ttdeci">vx_size padding_y</div><div class="ttdoc">Number of elements added at each side in the y dimension of the input. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00183">vx_khr_nn.h:183</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga2f2dd3b8c00370e78552ef64bb2a174c"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga2f2dd3b8c00370e78552ef64bb2a174c">vxNormalizationLayer</a></div><div class="ttdeci">vx_node vxNormalizationLayer(vx_graph graph, vx_tensor inputs, vx_enum type, vx_size normalization_size, vx_float32 alpha, vx_float32 beta, vx_tensor outputs)</div><div class="ttdoc">[Graph] Creates a Convolutional Network Normalization Layer Node. This function is optional for 8-bit...</div></div>
<div class="ttc" id="group__group__cnn_html_dd/d1b/structvx__nn__convolution__params__t"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a></div><div class="ttdoc">Input parameters for a convolution operation. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00180">vx_khr_nn.h:180</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga27a8a65bf3129353d6446474b0b78164a93013c97c0c22dfc6e165e636616da56"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a93013c97c0c22dfc6e165e636616da56">VX_TYPE_NN_DECONVOLUTION_PARAMS</a></div><div class="ttdoc">A vx_nn_deconvolution_params_t. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00173">vx_khr_nn.h:173</a></div></div>
<div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efa10c8eec4ac69b37a90b34d9751aefc31"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa10c8eec4ac69b37a90b34d9751aefc31">VX_KERNEL_CONVOLUTION_LAYER</a></div><div class="ttdoc">The Neural Network Extension convolution Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00055">vx_khr_nn.h:55</a></div></div>
<div class="ttc" id="group__group__cnn_html_aaa91b1e661cbcb791ee28274d220e85b"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#aaa91b1e661cbcb791ee28274d220e85b">vx_nn_deconvolution_params_t::a_y</a></div><div class="ttdeci">vx_size a_y</div><div class="ttdoc">user-specified quantity used to distinguish between the  different possible output sizes...</div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00202">vx_khr_nn.h:202</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga187a95c41a5802659b184f46991c1147"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a></div><div class="ttdeci">#define VX_LIBRARY_KHR_NN_EXTENSION</div><div class="ttdoc">The Neural Network Extension Library Set. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00046">vx_khr_nn.h:46</a></div></div>
<div class="ttc" id="group__group__cnn_html_d9/d91/structvx__nn__deconvolution__params__t"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a></div><div class="ttdoc">Input parameters for a deconvolution operation. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00195">vx_khr_nn.h:195</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga27a8a65bf3129353d6446474b0b78164"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga27a8a65bf3129353d6446474b0b78164">vx_nn_type_e</a></div><div class="ttdeci">vx_nn_type_e</div><div class="ttdoc">The type enumeration lists all NN extension types. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00171">vx_khr_nn.h:171</a></div></div>
<div class="ttc" id="group__group__cnn_html_a1a3c3ebf7954bd120ed6fd91debeeb42"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#a1a3c3ebf7954bd120ed6fd91debeeb42">vx_nn_convolution_params_t::rounding_policy</a></div><div class="ttdeci">vx_enum rounding_policy</div><div class="ttdoc">A  VX_TYPE_ENUM of the  vx_round_policy_e enumeration. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00185">vx_khr_nn.h:185</a></div></div>
<div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efa270b8ce654066df27b279fdec4b07bdf"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa270b8ce654066df27b279fdec4b07bdf">VX_KERNEL_SOFTMAX_LAYER</a></div><div class="ttdoc">The Neural Network Extension softmax Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00067">vx_khr_nn.h:67</a></div></div>
<div class="ttc" id="group__group__cnn_html_gaf28d53e554beba3da27f70fcd63895af"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">vx_nn_activation_function_e</a></div><div class="ttdeci">vx_nn_activation_function_e</div><div class="ttdoc">The Neural Network activation functions list. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00154">vx_khr_nn.h:154</a></div></div>
<div class="ttc" id="group__group__cnn_html_d6/d8c/structvx__nn__roi__pool__params__t"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">vx_nn_roi_pool_params_t</a></div><div class="ttdoc">Input parameters for ROI pooling operation. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00208">vx_khr_nn.h:208</a></div></div>
<div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efa839fdec645115663c8ecd71238d5353f"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa839fdec645115663c8ecd71238d5353f">VX_KERNEL_NORMALIZATION_LAYER</a></div><div class="ttdoc">The Neural Network Extension normalization Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00071">vx_khr_nn.h:71</a></div></div>
<div class="ttc" id="group__group__cnn_html_ad55be69baba9c172496b79a9756a7115"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ad55be69baba9c172496b79a9756a7115">vx_nn_deconvolution_params_t::padding_y</a></div><div class="ttdeci">vx_size padding_y</div><div class="ttdoc">Number of elements subtracted at each side in the y dimension of the output. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00198">vx_khr_nn.h:198</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga5edc475524c86e326b56ffaa7e8eaa28ae67da78d606b251db59482d18ca889ae"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28ae67da78d606b251db59482d18ca889ae">VX_NN_NORMALIZATION_SAME_MAP</a></div><div class="ttdoc">normalization is done on same IFM </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00131">vx_khr_nn.h:131</a></div></div>
<div class="ttc" id="group__group__cnn_html_gac4e286be0f9c9a2fbd3019fd74531332"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gac4e286be0f9c9a2fbd3019fd74531332">vxPoolingLayer</a></div><div class="ttdeci">vx_node vxPoolingLayer(vx_graph graph, vx_tensor inputs, vx_enum pooling_type, vx_size pooling_size_x, vx_size pooling_size_y, vx_size pooling_padding_x, vx_size pooling_padding_y, vx_enum rounding, vx_tensor outputs)</div><div class="ttdoc">[Graph] Creates a Convolutional Network Pooling Layer Node. </div></div>
<div class="ttc" id="group__group__cnn_html_aaa9dcb4ba92e41fcd8098f466a7a888e"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#aaa9dcb4ba92e41fcd8098f466a7a888e">vx_nn_deconvolution_params_t::padding_x</a></div><div class="ttdeci">vx_size padding_x</div><div class="ttdoc">Number of elements subtracted at each side in the x dimension of the output. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00197">vx_khr_nn.h:197</a></div></div>
<div class="ttc" id="group__group__cnn_html_ggad499c32ff42607fcffda9c3cca7185efa3269ace450aac7e30be256d5a3efcc8c"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa3269ace450aac7e30be256d5a3efcc8c">VX_KERNEL_FULLY_CONNECTED_LAYER</a></div><div class="ttdoc">The Neural Network Extension fully connected Kernel. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00059">vx_khr_nn.h:59</a></div></div>
<div class="ttc" id="group__group__cnn_html_gga86bbe62218962d22af01d434a42603c6ad6a16dde063af1e7b3797cd5c3d58415"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6ad6a16dde063af1e7b3797cd5c3d58415">VX_NN_DS_SIZE_ROUNDING_CEILING</a></div><div class="ttdoc">ceil rounding </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00108">vx_khr_nn.h:108</a></div></div>
<div class="ttc" id="group__group__cnn_html_ae172ac2cf9d292e38af5b394b4724d64"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ae172ac2cf9d292e38af5b394b4724d64">vx_nn_convolution_params_t::padding_x</a></div><div class="ttdeci">vx_size padding_x</div><div class="ttdoc">Number of elements added at each side in the x dimension of the input. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00182">vx_khr_nn.h:182</a></div></div>
<div class="ttc" id="group__group__cnn_html_ga69764625f436c14d739fc467515c1584"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga69764625f436c14d739fc467515c1584">vxConvolutionLayer</a></div><div class="ttdeci">vx_node vxConvolutionLayer(vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, vx_nn_convolution_params_t *convolution_params, vx_size size_of_convolution_params, vx_tensor outputs)</div><div class="ttdoc">[Graph] Creates a Convolutional Network Convolution Layer Node. </div></div>
<div class="ttc" id="group__group__cnn_html_ga5edc475524c86e326b56ffaa7e8eaa28"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#ga5edc475524c86e326b56ffaa7e8eaa28">vx_nn_norm_type_e</a></div><div class="ttdeci">vx_nn_norm_type_e</div><div class="ttdoc">The Neural Network normalization type list. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00128">vx_khr_nn.h:128</a></div></div>
<div class="ttc" id="group__group__cnn_html_a713d31f84f4d45780b6f8f7236c4f456"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#a713d31f84f4d45780b6f8f7236c4f456">vx_nn_convolution_params_t::dilation_x</a></div><div class="ttdeci">vx_size dilation_x</div><div class="ttdoc">“inflate” the kernel by inserting zeros between the kernel elements in the x direction. The value is the number of zeros to insert. </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00187">vx_khr_nn.h:187</a></div></div>
<div class="ttc" id="group__group__cnn_html_a5296a774c77309f9f9ead807445be56f"><div class="ttname"><a href="../../d6/d9a/group__group__cnn.html#a5296a774c77309f9f9ead807445be56f">vx_nn_convolution_params_t::down_scale_size_rounding</a></div><div class="ttdeci">vx_enum down_scale_size_rounding</div><div class="ttdoc">Rounding method for calculating output dimensions. See vx_nn_rounding_type_e </div><div class="ttdef"><b>Definition:</b> <a href="../../db/d9c/vx__khr__nn_8h_source.html#l00186">vx_khr_nn.h:186</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="../../dir_a3324bfc7e66844c57dfd3bddf0b96d4.html">VX</a></li><li class="navelem"><b>vx_khr_nn.h</b></li>
    <li class="footer">Generated on Wed Nov 8 2017 12:35:16 for OpenVX Neural Network Extension by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="../../doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
