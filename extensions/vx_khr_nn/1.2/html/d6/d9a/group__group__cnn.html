<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>OpenVX Neural Network Extension: Extension: Deep Convolutional Networks API</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../OpenVX_170px_June16.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">OpenVX Neural Network Extension
   &#160;<span id="projectnumber">02b8d012</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('d6/d9a/group__group__cnn.html','../../');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Data Structures</a> &#124;
<a href="#define-members">Macros</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Extension: Deep Convolutional Networks API</div>  </div>
</div><!--header-->
<div class="contents">

<p>Convolutional Network Nodes.  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Data Structures</h2></td></tr>
<tr class="memitem:dd/d1b/structvx__nn__convolution__params__t"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a></td></tr>
<tr class="memdesc:dd/d1b/structvx__nn__convolution__params__t"><td class="mdescLeft">&#160;</td><td class="mdescRight">Input parameters for a convolution operation.  <a href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">More...</a><br /></td></tr>
<tr class="separator:dd/d1b/structvx__nn__convolution__params__t"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:d9/d91/structvx__nn__deconvolution__params__t"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a></td></tr>
<tr class="memdesc:d9/d91/structvx__nn__deconvolution__params__t"><td class="mdescLeft">&#160;</td><td class="mdescRight">Input parameters for a deconvolution operation.  <a href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">More...</a><br /></td></tr>
<tr class="separator:d9/d91/structvx__nn__deconvolution__params__t"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:d6/d8c/structvx__nn__roi__pool__params__t"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">vx_nn_roi_pool_params_t</a></td></tr>
<tr class="memdesc:d6/d8c/structvx__nn__roi__pool__params__t"><td class="mdescLeft">&#160;</td><td class="mdescRight">Input parameters for ROI pooling operation.  <a href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">More...</a><br /></td></tr>
<tr class="separator:d6/d8c/structvx__nn__roi__pool__params__t"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="define-members"></a>
Macros</h2></td></tr>
<tr class="memitem:ga187a95c41a5802659b184f46991c1147"><td class="memItemLeft" align="right" valign="top"><a id="ga187a95c41a5802659b184f46991c1147"></a>
#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga187a95c41a5802659b184f46991c1147">VX_LIBRARY_KHR_NN_EXTENSION</a>&#160;&#160;&#160;(0x1)</td></tr>
<tr class="memdesc:ga187a95c41a5802659b184f46991c1147"><td class="mdescLeft">&#160;</td><td class="mdescRight">The Neural Network Extension Library Set. <br /></td></tr>
<tr class="separator:ga187a95c41a5802659b184f46991c1147"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:gad499c32ff42607fcffda9c3cca7185ef"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#gad499c32ff42607fcffda9c3cca7185ef">vx_kernel_nn_ext_e</a> { <br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa10c8eec4ac69b37a90b34d9751aefc31">VX_KERNEL_CONVOLUTION_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x0, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa3269ace450aac7e30be256d5a3efcc8c">VX_KERNEL_FULLY_CONNECTED_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x1, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efad75b4eaef510d969e412aa08d2cb3edc">VX_KERNEL_POOLING_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x2, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa270b8ce654066df27b279fdec4b07bdf">VX_KERNEL_SOFTMAX_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x3, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa839fdec645115663c8ecd71238d5353f">VX_KERNEL_NORMALIZATION_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x4, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efafcfbeeb8d83b4ae949ec8fd06c7dcc19">VX_KERNEL_ACTIVATION_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x5, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa04b0137b6e503e303c75f38da895cfe9">VX_KERNEL_ROI_POOLING_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x6, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#ggad499c32ff42607fcffda9c3cca7185efa0993f051aa373134ea832496168d6fed">VX_KERNEL_DECONVOLUTION_LAYER</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( (0x1) &lt;&lt; 12)) + 0x7
<br />
 }<tr class="memdesc:gad499c32ff42607fcffda9c3cca7185ef"><td class="mdescLeft">&#160;</td><td class="mdescRight">The list of Neural Network Extension Kernels.  <a href="../../d6/d9a/group__group__cnn.html#gad499c32ff42607fcffda9c3cca7185ef">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:gad499c32ff42607fcffda9c3cca7185ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf28d53e554beba3da27f70fcd63895af"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">vx_nn_activation_function_e</a> { <br />
&#160;&#160;<b>VX_NN_ACTIVATION_LOGISTIC</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x0, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_HYPERBOLIC_TAN</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x1, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_RELU</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x2, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_BRELU</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x3, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_SOFTRELU</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x4, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_ABS</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x5, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_SQUARE</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x6, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_SQRT</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x7, 
<br />
&#160;&#160;<b>VX_NN_ACTIVATION_LINEAR</b> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE &lt;&lt; 12)) + 0x8
<br />
 }<tr class="memdesc:gaf28d53e554beba3da27f70fcd63895af"><td class="mdescLeft">&#160;</td><td class="mdescRight">The Neural Network activation functions list.  <a href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:gaf28d53e554beba3da27f70fcd63895af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae5b5a30ecdff611b248b26f65d7aa900"><td class="memItemLeft" align="right" valign="top"><a id="gae5b5a30ecdff611b248b26f65d7aa900"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#gae5b5a30ecdff611b248b26f65d7aa900">vx_nn_enum_e</a> { <br />
&#160;&#160;<b>VX_ENUM_NN_ROUNDING_TYPE</b> = 0x1A, 
<br />
&#160;&#160;<b>VX_ENUM_NN_POOLING_TYPE</b> = 0x1B, 
<br />
&#160;&#160;<b>VX_ENUM_NN_NORMALIZATION_TYPE</b> = 0x1C, 
<br />
&#160;&#160;<b>VX_ENUM_NN_ACTIVATION_FUNCTION_TYPE</b> = 0x1D
<br />
 }<tr class="memdesc:gae5b5a30ecdff611b248b26f65d7aa900"><td class="mdescLeft">&#160;</td><td class="mdescRight">NN extension type enums. <br /></td></tr>
</td></tr>
<tr class="separator:gae5b5a30ecdff611b248b26f65d7aa900"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5edc475524c86e326b56ffaa7e8eaa28"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga5edc475524c86e326b56ffaa7e8eaa28">vx_nn_norm_type_e</a> { <br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28ae67da78d606b251db59482d18ca889ae">VX_NN_NORMALIZATION_SAME_MAP</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_NORMALIZATION_TYPE &lt;&lt; 12)) + 0x0, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga5edc475524c86e326b56ffaa7e8eaa28a9cb28001c736aa33d54a839e812a40ed">VX_NN_NORMALIZATION_ACROSS_MAPS</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_NORMALIZATION_TYPE &lt;&lt; 12)) + 0x1
<br />
 }<tr class="memdesc:ga5edc475524c86e326b56ffaa7e8eaa28"><td class="mdescLeft">&#160;</td><td class="mdescRight">The Neural Network normalization type list.  <a href="../../d6/d9a/group__group__cnn.html#ga5edc475524c86e326b56ffaa7e8eaa28">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:ga5edc475524c86e326b56ffaa7e8eaa28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga516b0d3e8da43e82826bcccfc196c3e2"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">vx_nn_pooling_type_e</a> { <br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc">VX_NN_POOLING_MAX</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_POOLING_TYPE &lt;&lt; 12)) + 0x0, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2add52234a10e4685d1958be373319741c">VX_NN_POOLING_AVG</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_POOLING_TYPE &lt;&lt; 12)) + 0x1
<br />
 }<tr class="memdesc:ga516b0d3e8da43e82826bcccfc196c3e2"><td class="mdescLeft">&#160;</td><td class="mdescRight">The Neural Network pooling type list.  <a href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:ga516b0d3e8da43e82826bcccfc196c3e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga86bbe62218962d22af01d434a42603c6"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a> { <br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6a2aa48ad506133fdf01c0bd37f6293860">VX_NN_DS_SIZE_ROUNDING_FLOOR</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ROUNDING_TYPE &lt;&lt; 12)) + 0x0, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga86bbe62218962d22af01d434a42603c6ad6a16dde063af1e7b3797cd5c3d58415">VX_NN_DS_SIZE_ROUNDING_CEILING</a> = ((( VX_ID_KHRONOS ) &lt;&lt; 20) | ( VX_ENUM_NN_ROUNDING_TYPE &lt;&lt; 12)) + 0x1
<br />
 }<tr class="memdesc:ga86bbe62218962d22af01d434a42603c6"><td class="mdescLeft">&#160;</td><td class="mdescRight">down scale rounding.  <a href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:ga86bbe62218962d22af01d434a42603c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga27a8a65bf3129353d6446474b0b78164"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga27a8a65bf3129353d6446474b0b78164">vx_nn_type_e</a> { <br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a411116ea30558ddbf45dc7db2074522f">VX_TYPE_NN_CONVOLUTION_PARAMS</a> = 0x025, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164a93013c97c0c22dfc6e165e636616da56">VX_TYPE_NN_DECONVOLUTION_PARAMS</a> = 0x026, 
<br />
&#160;&#160;<a class="el" href="../../d6/d9a/group__group__cnn.html#gga27a8a65bf3129353d6446474b0b78164af06282ca200b459a31d85e09aec81cc1">VX_TYPE_NN_ROI_POOL_PARAMS</a> = 0x027
<br />
 }<tr class="memdesc:ga27a8a65bf3129353d6446474b0b78164"><td class="mdescLeft">&#160;</td><td class="mdescRight">The type enumeration lists all NN extension types.  <a href="../../d6/d9a/group__group__cnn.html#ga27a8a65bf3129353d6446474b0b78164">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:ga27a8a65bf3129353d6446474b0b78164"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga81fccaa902dfe507dace415f189d5e5e"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga81fccaa902dfe507dace415f189d5e5e">vxActivationLayer</a> (vx_graph graph, vx_tensor inputs, vx_enum function, vx_float32 a, vx_float32 b, vx_tensor outputs)</td></tr>
<tr class="memdesc:ga81fccaa902dfe507dace415f189d5e5e"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Convolutional Network Activation Layer Node. The function operate a specific function (Specified in <code><a class="el" href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">vx_nn_activation_function_e</a></code>), On the input data. the equation for the layer is: \( outputs(i,j,k,l) = function(inputs(i,j,k,l), a, b) \) for all i,j,k,l.  <a href="#ga81fccaa902dfe507dace415f189d5e5e">More...</a><br /></td></tr>
<tr class="separator:ga81fccaa902dfe507dace415f189d5e5e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga69764625f436c14d739fc467515c1584"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga69764625f436c14d739fc467515c1584">vxConvolutionLayer</a> (vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, <a class="el" href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a> *convolution_params, vx_size size_of_convolution_params, vx_tensor outputs)</td></tr>
<tr class="memdesc:ga69764625f436c14d739fc467515c1584"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Convolutional Network Convolution Layer Node.  <a href="#ga69764625f436c14d739fc467515c1584">More...</a><br /></td></tr>
<tr class="separator:ga69764625f436c14d739fc467515c1584"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5c056442529c4c979eb6b82d81cab907"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga5c056442529c4c979eb6b82d81cab907">vxDeconvolutionLayer</a> (vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, <a class="el" href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a> *deconvolution_params, vx_size size_of_deconv_params, vx_tensor outputs)</td></tr>
<tr class="memdesc:ga5c056442529c4c979eb6b82d81cab907"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Convolutional Network Deconvolution Layer Node.  <a href="#ga5c056442529c4c979eb6b82d81cab907">More...</a><br /></td></tr>
<tr class="separator:ga5c056442529c4c979eb6b82d81cab907"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga70f11e4a18658dd8753f9d8e009730b2"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga70f11e4a18658dd8753f9d8e009730b2">vxFullyConnectedLayer</a> (vx_graph graph, vx_tensor inputs, vx_tensor weights, vx_tensor biases, vx_enum overflow_policy, vx_enum rounding_policy, vx_tensor outputs)</td></tr>
<tr class="memdesc:ga70f11e4a18658dd8753f9d8e009730b2"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Fully connected Convolutional Network Layer Node.  <a href="#ga70f11e4a18658dd8753f9d8e009730b2">More...</a><br /></td></tr>
<tr class="separator:ga70f11e4a18658dd8753f9d8e009730b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2f2dd3b8c00370e78552ef64bb2a174c"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga2f2dd3b8c00370e78552ef64bb2a174c">vxNormalizationLayer</a> (vx_graph graph, vx_tensor inputs, vx_enum type, vx_size normalization_size, vx_float32 alpha, vx_float32 beta, vx_tensor outputs)</td></tr>
<tr class="memdesc:ga2f2dd3b8c00370e78552ef64bb2a174c"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Convolutional Network Normalization Layer Node. This function is optional for 8-bit extension with the extension string 'KHR_NN_8'.  <a href="#ga2f2dd3b8c00370e78552ef64bb2a174c">More...</a><br /></td></tr>
<tr class="separator:ga2f2dd3b8c00370e78552ef64bb2a174c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac4e286be0f9c9a2fbd3019fd74531332"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#gac4e286be0f9c9a2fbd3019fd74531332">vxPoolingLayer</a> (vx_graph graph, vx_tensor inputs, vx_enum pooling_type, vx_size pooling_size_x, vx_size pooling_size_y, vx_size pooling_padding_x, vx_size pooling_padding_y, vx_enum rounding, vx_tensor outputs)</td></tr>
<tr class="memdesc:gac4e286be0f9c9a2fbd3019fd74531332"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Convolutional Network Pooling Layer Node.  <a href="#gac4e286be0f9c9a2fbd3019fd74531332">More...</a><br /></td></tr>
<tr class="separator:gac4e286be0f9c9a2fbd3019fd74531332"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae80cce7ad61e5b4ac9e1c1136f40d65e"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#gae80cce7ad61e5b4ac9e1c1136f40d65e">vxROIPoolingLayer</a> (vx_graph graph, vx_tensor input_data, vx_tensor input_rois, <a class="el" href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">vx_nn_roi_pool_params_t</a> *roi_pool_params, vx_size size_of_roi_params, vx_tensor output_arr)</td></tr>
<tr class="memdesc:gae80cce7ad61e5b4ac9e1c1136f40d65e"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Convolutional Network ROI pooling node  <a href="#gae80cce7ad61e5b4ac9e1c1136f40d65e">More...</a><br /></td></tr>
<tr class="separator:gae80cce7ad61e5b4ac9e1c1136f40d65e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga76a3a94a73992017519d7dc01e81c476"><td class="memItemLeft" align="right" valign="top">vx_node&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d6/d9a/group__group__cnn.html#ga76a3a94a73992017519d7dc01e81c476">vxSoftmaxLayer</a> (vx_graph graph, vx_tensor inputs, vx_tensor outputs)</td></tr>
<tr class="memdesc:ga76a3a94a73992017519d7dc01e81c476"><td class="mdescLeft">&#160;</td><td class="mdescRight">[Graph] Creates a Convolutional Network Softmax Layer Node.  <a href="#ga76a3a94a73992017519d7dc01e81c476">More...</a><br /></td></tr>
<tr class="separator:ga76a3a94a73992017519d7dc01e81c476"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>Convolutional Network Nodes. </p>
<hr/><h2 class="groupheader">Data Structure Documentation</h2>
<a name="dd/d1b/structvx__nn__convolution__params__t" id="dd/d1b/structvx__nn__convolution__params__t"></a>
<h2 class="memtitle"><span class="permalink"><a href="#dd/d1b/structvx__nn__convolution__params__t">&#9670;&nbsp;</a></span>vx_nn_convolution_params_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">struct vx_nn_convolution_params_t</td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="textblock"><p>Input parameters for a convolution operation. </p>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00180">180</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>
</div><div class="dynheader">
Collaboration diagram for vx_nn_convolution_params_t:</div>
<div class="dyncontent">
<div class="center"><img src="../../d3/d43/structvx__nn__convolution__params__t__coll__graph.png" border="0" usemap="#vx__nn__convolution__params__t_coll__map" alt="Collaboration graph"/></div>
<map name="vx__nn__convolution__params__t_coll__map" id="vx__nn__convolution__params__t_coll__map">
</map>
</div>
<table class="fieldtable">
<tr><th colspan="3">Data Fields</th></tr>
<tr><td class="fieldtype">
<a id="a713d31f84f4d45780b6f8f7236c4f456"></a>vx_size</td>
<td class="fieldname">
dilation_x</td>
<td class="fielddoc">
“inflate” the kernel by inserting zeros between the kernel elements in the x direction. The value is the number of zeros to insert. </td></tr>
<tr><td class="fieldtype">
<a id="a455f16c8987d05355d77ceb22c2e9dd6"></a>vx_size</td>
<td class="fieldname">
dilation_y</td>
<td class="fielddoc">
“inflate” the kernel by inserting zeros between the kernel elements in the y direction. The value is the number of zeros to insert. </td></tr>
<tr><td class="fieldtype">
<a id="a5296a774c77309f9f9ead807445be56f"></a>vx_enum</td>
<td class="fieldname">
down_scale_size_rounding</td>
<td class="fielddoc">
Rounding method for calculating output dimensions. See <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a></code> </td></tr>
<tr><td class="fieldtype">
<a id="a5fb7b1019861afc6098197139bc991bc"></a>vx_enum</td>
<td class="fieldname">
overflow_policy</td>
<td class="fielddoc">
A <code> VX_TYPE_ENUM</code> of the <code> vx_convert_policy_e</code> enumeration. </td></tr>
<tr><td class="fieldtype">
<a id="ae172ac2cf9d292e38af5b394b4724d64"></a>vx_size</td>
<td class="fieldname">
padding_x</td>
<td class="fielddoc">
Number of elements added at each side in the x dimension of the input. </td></tr>
<tr><td class="fieldtype">
<a id="ac420cbc3cb68cc9786c4050892df95a4"></a>vx_size</td>
<td class="fieldname">
padding_y</td>
<td class="fielddoc">
Number of elements added at each side in the y dimension of the input. </td></tr>
<tr><td class="fieldtype">
<a id="a1a3c3ebf7954bd120ed6fd91debeeb42"></a>vx_enum</td>
<td class="fieldname">
rounding_policy</td>
<td class="fielddoc">
A <code> VX_TYPE_ENUM</code> of the <code> vx_round_policy_e</code> enumeration. </td></tr>
</table>

</div>
</div>
<a name="d9/d91/structvx__nn__deconvolution__params__t" id="d9/d91/structvx__nn__deconvolution__params__t"></a>
<h2 class="memtitle"><span class="permalink"><a href="#d9/d91/structvx__nn__deconvolution__params__t">&#9670;&nbsp;</a></span>vx_nn_deconvolution_params_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">struct vx_nn_deconvolution_params_t</td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="textblock"><p>Input parameters for a deconvolution operation. </p>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00195">195</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>
</div><div class="dynheader">
Collaboration diagram for vx_nn_deconvolution_params_t:</div>
<div class="dyncontent">
<div class="center"><img src="../../d3/dd8/structvx__nn__deconvolution__params__t__coll__graph.png" border="0" usemap="#vx__nn__deconvolution__params__t_coll__map" alt="Collaboration graph"/></div>
<map name="vx__nn__deconvolution__params__t_coll__map" id="vx__nn__deconvolution__params__t_coll__map">
</map>
</div>
<table class="fieldtable">
<tr><th colspan="3">Data Fields</th></tr>
<tr><td class="fieldtype">
<a id="a154d04fd1c8f67a4b98f7b4aa7460ccb"></a>vx_size</td>
<td class="fieldname">
a_x</td>
<td class="fielddoc">
user-specified quantity used to distinguish between the \(upscale_x\) different possible output sizes. </td></tr>
<tr><td class="fieldtype">
<a id="aaa91b1e661cbcb791ee28274d220e85b"></a>vx_size</td>
<td class="fieldname">
a_y</td>
<td class="fielddoc">
user-specified quantity used to distinguish between the \(upscale_y\) different possible output sizes. </td></tr>
<tr><td class="fieldtype">
<a id="a454f2e9685c4efb4c2437ebef44602b4"></a>vx_enum</td>
<td class="fieldname">
overflow_policy</td>
<td class="fielddoc">
A <code> VX_TYPE_ENUM</code> of the <code> vx_convert_policy_e</code> enumeration. </td></tr>
<tr><td class="fieldtype">
<a id="aaa9dcb4ba92e41fcd8098f466a7a888e"></a>vx_size</td>
<td class="fieldname">
padding_x</td>
<td class="fielddoc">
Number of elements subtracted at each side in the x dimension of the output. </td></tr>
<tr><td class="fieldtype">
<a id="ad55be69baba9c172496b79a9756a7115"></a>vx_size</td>
<td class="fieldname">
padding_y</td>
<td class="fielddoc">
Number of elements subtracted at each side in the y dimension of the output. </td></tr>
<tr><td class="fieldtype">
<a id="af5f8d839a7182f7d1890b2469df5a07c"></a>vx_enum</td>
<td class="fieldname">
rounding_policy</td>
<td class="fielddoc">
A <code> VX_TYPE_ENUM</code> of the <code> vx_round_policy_e</code> enumeration. </td></tr>
</table>

</div>
</div>
<a name="d6/d8c/structvx__nn__roi__pool__params__t" id="d6/d8c/structvx__nn__roi__pool__params__t"></a>
<h2 class="memtitle"><span class="permalink"><a href="#d6/d8c/structvx__nn__roi__pool__params__t">&#9670;&nbsp;</a></span>vx_nn_roi_pool_params_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">struct vx_nn_roi_pool_params_t</td>
        </tr>
      </table>
</div><div class="memdoc">
<div class="textblock"><p>Input parameters for ROI pooling operation. </p>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00208">208</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>
</div><div class="dynheader">
Collaboration diagram for vx_nn_roi_pool_params_t:</div>
<div class="dyncontent">
<div class="center"><img src="../../d7/d3f/structvx__nn__roi__pool__params__t__coll__graph.png" border="0" usemap="#vx__nn__roi__pool__params__t_coll__map" alt="Collaboration graph"/></div>
<map name="vx__nn__roi__pool__params__t_coll__map" id="vx__nn__roi__pool__params__t_coll__map">
</map>
</div>
<table class="fieldtable">
<tr><th colspan="3">Data Fields</th></tr>
<tr><td class="fieldtype">
<a id="ad8cb5ae660ac3040ea8fb2f965ed3c75"></a>vx_enum</td>
<td class="fieldname">
pool_type</td>
<td class="fielddoc">
Of type <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">vx_nn_pooling_type_e</a></code>. Only <code><a class="el" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc">VX_NN_POOLING_MAX</a></code> pooling is supported. </td></tr>
</table>

</div>
</div>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="gad499c32ff42607fcffda9c3cca7185ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad499c32ff42607fcffda9c3cca7185ef">&#9670;&nbsp;</a></span>vx_kernel_nn_ext_e</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="../../d6/d9a/group__group__cnn.html#gad499c32ff42607fcffda9c3cca7185ef">vx_kernel_nn_ext_e</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The list of Neural Network Extension Kernels. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efa10c8eec4ac69b37a90b34d9751aefc31"></a>VX_KERNEL_CONVOLUTION_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network Extension convolution Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
<tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efa3269ace450aac7e30be256d5a3efcc8c"></a>VX_KERNEL_FULLY_CONNECTED_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network Extension fully connected Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
<tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efad75b4eaef510d969e412aa08d2cb3edc"></a>VX_KERNEL_POOLING_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network Extension pooling Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
<tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efa270b8ce654066df27b279fdec4b07bdf"></a>VX_KERNEL_SOFTMAX_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network Extension softmax Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
<tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efa839fdec645115663c8ecd71238d5353f"></a>VX_KERNEL_NORMALIZATION_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network Extension normalization Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
<tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efafcfbeeb8d83b4ae949ec8fd06c7dcc19"></a>VX_KERNEL_ACTIVATION_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network Extension activation Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
<tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efa04b0137b6e503e303c75f38da895cfe9"></a>VX_KERNEL_ROI_POOLING_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network POI Pooling Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
<tr><td class="fieldname"><a id="ggad499c32ff42607fcffda9c3cca7185efa0993f051aa373134ea832496168d6fed"></a>VX_KERNEL_DECONVOLUTION_LAYER&#160;</td><td class="fielddoc"><p>The Neural Network Extension Deconvolution Kernel. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="../../d6/d9a/group__group__cnn.html" title="Convolutional Network Nodes. ">Extension: Deep Convolutional Networks API</a> </dd></dl>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00051">51</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>

</div>
</div>
<a id="gaf28d53e554beba3da27f70fcd63895af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf28d53e554beba3da27f70fcd63895af">&#9670;&nbsp;</a></span>vx_nn_activation_function_e</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">vx_nn_activation_function_e</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The Neural Network activation functions list. </p>
<table class="doxtable">
<tr>
<td><b>Function name </b> </td><td><b>Mathematical definition</b> </td><td><b>Parameters</b> </td><td><b>Parameters type</b> </td></tr>
<tr>
<td>logistic </td><td>\(f(x)=1/(1+e^{-x}) \) </td><td></td><td></td></tr>
<tr>
<td>hyperbolic tangent </td><td>\(f(x)=a\cdot tanh(b\cdot x) \) </td><td>a,b </td><td>VX_FLOAT32 </td></tr>
<tr>
<td>relu </td><td>\(f(x)=max(0,x)\) </td><td></td><td></td></tr>
<tr>
<td>bounded relu </td><td>\(f(x)=min(a,max(0,x)) \) </td><td>a </td><td>VX_FLOAT32 </td></tr>
<tr>
<td>soft relu </td><td>\(f(x)=log(1+e^{x}) \) </td><td></td><td></td></tr>
<tr>
<td>abs </td><td>\(f(x)=\mid x\mid \) </td><td></td><td></td></tr>
<tr>
<td>square </td><td>\(f(x)= x^2 \) </td><td></td><td></td></tr>
<tr>
<td>square root </td><td>\(f(x)=\sqrt{x} \) </td><td></td><td></td></tr>
<tr>
<td>linear </td><td>\(f(x)=ax+b \) </td><td>a,b </td><td>VX_FLOAT32 </td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00154">154</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>

</div>
</div>
<a id="ga5edc475524c86e326b56ffaa7e8eaa28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5edc475524c86e326b56ffaa7e8eaa28">&#9670;&nbsp;</a></span>vx_nn_norm_type_e</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="../../d6/d9a/group__group__cnn.html#ga5edc475524c86e326b56ffaa7e8eaa28">vx_nn_norm_type_e</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The Neural Network normalization type list. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga5edc475524c86e326b56ffaa7e8eaa28ae67da78d606b251db59482d18ca889ae"></a>VX_NN_NORMALIZATION_SAME_MAP&#160;</td><td class="fielddoc"><p>normalization is done on same IFM </p>
</td></tr>
<tr><td class="fieldname"><a id="gga5edc475524c86e326b56ffaa7e8eaa28a9cb28001c736aa33d54a839e812a40ed"></a>VX_NN_NORMALIZATION_ACROSS_MAPS&#160;</td><td class="fielddoc"><p>Normalization is done across different IFMs. </p>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00128">128</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>

</div>
</div>
<a id="ga516b0d3e8da43e82826bcccfc196c3e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga516b0d3e8da43e82826bcccfc196c3e2">&#9670;&nbsp;</a></span>vx_nn_pooling_type_e</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">vx_nn_pooling_type_e</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The Neural Network pooling type list. </p>
<p>kind of pooling done in pooling function </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc"></a>VX_NN_POOLING_MAX&#160;</td><td class="fielddoc"><p>max pooling </p>
</td></tr>
<tr><td class="fieldname"><a id="gga516b0d3e8da43e82826bcccfc196c3e2add52234a10e4685d1958be373319741c"></a>VX_NN_POOLING_AVG&#160;</td><td class="fielddoc"><p>average pooling </p>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00116">116</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>

</div>
</div>
<a id="ga86bbe62218962d22af01d434a42603c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga86bbe62218962d22af01d434a42603c6">&#9670;&nbsp;</a></span>vx_nn_rounding_type_e</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>down scale rounding. </p>
<p>Due to different scheme of downscale size calculation in the various training frameworks. Implementation must support 2 rounding methods for down scale calculation. The floor and the ceiling. In convolution and pooling functions. Relevant when input size is even. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga86bbe62218962d22af01d434a42603c6a2aa48ad506133fdf01c0bd37f6293860"></a>VX_NN_DS_SIZE_ROUNDING_FLOOR&#160;</td><td class="fielddoc"><p>floor rounding </p>
</td></tr>
<tr><td class="fieldname"><a id="gga86bbe62218962d22af01d434a42603c6ad6a16dde063af1e7b3797cd5c3d58415"></a>VX_NN_DS_SIZE_ROUNDING_CEILING&#160;</td><td class="fielddoc"><p>ceil rounding </p>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00103">103</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>

</div>
</div>
<a id="ga27a8a65bf3129353d6446474b0b78164"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga27a8a65bf3129353d6446474b0b78164">&#9670;&nbsp;</a></span>vx_nn_type_e</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="../../d6/d9a/group__group__cnn.html#ga27a8a65bf3129353d6446474b0b78164">vx_nn_type_e</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The type enumeration lists all NN extension types. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga27a8a65bf3129353d6446474b0b78164a411116ea30558ddbf45dc7db2074522f"></a>VX_TYPE_NN_CONVOLUTION_PARAMS&#160;</td><td class="fielddoc"><p>A <code><a class="el" href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a></code>. </p>
</td></tr>
<tr><td class="fieldname"><a id="gga27a8a65bf3129353d6446474b0b78164a93013c97c0c22dfc6e165e636616da56"></a>VX_TYPE_NN_DECONVOLUTION_PARAMS&#160;</td><td class="fielddoc"><p>A <code><a class="el" href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a></code>. </p>
</td></tr>
<tr><td class="fieldname"><a id="gga27a8a65bf3129353d6446474b0b78164af06282ca200b459a31d85e09aec81cc1"></a>VX_TYPE_NN_ROI_POOL_PARAMS&#160;</td><td class="fielddoc"><p>A <code><a class="el" href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">vx_nn_roi_pool_params_t</a></code>. </p>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html#l00171">171</a> of file <a class="el" href="../../db/d9c/vx__khr__nn_8h_source.html">vx_khr_nn.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga81fccaa902dfe507dace415f189d5e5e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga81fccaa902dfe507dace415f189d5e5e">&#9670;&nbsp;</a></span>vxActivationLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxActivationLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_enum&#160;</td>
          <td class="paramname"><em>function</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_float32&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_float32&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Convolutional Network Activation Layer Node. The function operate a specific function (Specified in <code><a class="el" href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">vx_nn_activation_function_e</a></code>), On the input data. the equation for the layer is: \( outputs(i,j,k,l) = function(inputs(i,j,k,l), a, b) \) for all i,j,k,l. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor data. Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8' or 'KHR_NN_8 KHR_NN_16'. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">function</td><td>[static] Non-linear function (see <code><a class="el" href="../../d6/d9a/group__group__cnn.html#gaf28d53e554beba3da27f70fcd63895af">vx_nn_activation_function_e</a></code>). Implementations must support <code>VX_NN_ACTIVATION_LOGISTIC</code>, <code>VX_NN_ACTIVATION_HYPERBOLIC_TAN</code> and <code>VX_NN_ACTIVATION_RELU</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">a</td><td>[static] Function parameters a. must be positive. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">b</td><td>[static] Function parameters b. must be positive. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">outputs</td><td>The output tensor data. Output will have the same number of dimensions as input.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
<a id="ga69764625f436c14d739fc467515c1584"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga69764625f436c14d739fc467515c1584">&#9670;&nbsp;</a></span>vxConvolutionLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxConvolutionLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a> *&#160;</td>
          <td class="paramname"><em>convolution_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>size_of_convolution_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Convolutional Network Convolution Layer Node. </p>
<p>This function implement Convolutional Network Convolution layer. For fixed-point data types, a fixed point calculation is performed with round and saturate according to the number of accumulator bits. The number of the accumulator bits are implementation defined, and should be at least 16.<br />
round: rounding according the <code>vx_round_policy_e</code> enumeration. <br />
saturate: A saturation according the <code>vx_convert_policy_e</code> enumeration. The following equation is implemented: <br />
 \( outputs[j,k,i] = saturate(round(\sum_{l} (\sum_{m,n} inputs[j+m,k+n,l] \times weights[m,n,l,i])+biasses[j,k,i])) \)<br />
Where \(m,n\) are indexes on the convolution matrices. \( l\) is an index on all the convolutions per input. \( i\) is an index per output. \( j,k \) are the inputs/outputs spatial indexes. Convolution is done on the width and height dimensions of the <code>vx_tensor</code>. Therefore, we use here the term x for index along the width dimension and y for index along the height dimension.<br />
before the Convolution is done, a padding with zeros of the width and height input dimensions is performed. Then down scale is done by picking the results according to a skip jump. The skip in the x and y is determined by the output size dimensions. The relation between input to output is as follows: <br />
 \( width_{output} = round(\frac{(width_{input} + 2 * padding_x - kernel_x - (kernel_x -1) * dilation_x)}{skip_x} + 1) \)<br />
and <br />
 \( height_{output} = round(\frac{(height + 2 * padding_y - kernel_y - (kernel_y -1) * dilation_y)}{skip_y} + 1) \)<br />
 where \(width\) is the size of the input width dimension. \(height\) is the size of the input height dimension. \(width_{output}\) is the size of the output width dimension. \(height_{output}\) is the size of the output height dimension. \(kernel_x\) and \(kernel_y\) are the convolution sizes in width and height dimensions. skip is calculated by the relation between input and output. In case of ambiguity in the inverse calculation of the skip. The minimum solution is chosen. Skip must be a positive non zero integer. rounding is done according to <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a></code>. Notice that this node creation function has more parameters than the corresponding kernel. Numbering of kernel parameters (required if you create this node using the generic interface) is explicitly specified here. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor data. 3 lower dimensions represent a single input, all following dimensions represent number of batches, possibly nested. The dimension order is [width, height, #IFM, #batches]<br />
. Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8' or 'KHR_NN_8 KHR_NN_16'. (Kernel parameter #0) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>[static] Weights are 4d tensor with dimensions [kernel_x, kernel_y, #IFM, #OFM]. see <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code> <br />
 Weights data type must match the data type of the inputs. (Kernel parameter #1) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>[static] Optional, ignored if NULL. The biases, which may be shared (one per ofm) or unshared (one per ofm * output location). The possible layouts are either [#OFM] or [width, height, #OFM]. Biases data type must match the data type of the inputs. (Kernel parameter #2) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">convolution_params</td><td>[static] Pointer to parameters of type <code><a class="el" href="../../d6/d9a/group__group__cnn.html#dd/d1b/structvx__nn__convolution__params__t">vx_nn_convolution_params_t</a></code>. (Kernel parameter #3) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">size_of_convolution_params</td><td>[static] Size in bytes of convolution_params. Note that this parameter is not counted as one of the kernel parameters. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">outputs</td><td>The output tensor data. Output will have the same number and structure of dimensions as input. Output tensor data type must be same as the inputs. (Kernel parameter #4) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
<a id="ga5c056442529c4c979eb6b82d81cab907"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5c056442529c4c979eb6b82d81cab907">&#9670;&nbsp;</a></span>vxDeconvolutionLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxDeconvolutionLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a> *&#160;</td>
          <td class="paramname"><em>deconvolution_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>size_of_deconv_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Convolutional Network Deconvolution Layer Node. </p>
<p>Deconvolution denote a sort of reverse convolution, which importantly and confusingly is not actually a proper mathematical deconvolution. Convolutional Network Deconvolution is up-sampling of an image by learned Deconvolution coefficients. The operation is similar to convolution but can be implemented by up-sampling the inputs with zeros insertions between the inputs, and convolving the Deconvolution kernels on the up-sampled result. For fixed-point data types, a fixed point calculation is performed with round and saturate according to the number of accumulator bits. The number of the accumulator bits are implementation defined, and should be at least 16.<br />
round: rounding according the <code>vx_round_policy_e</code> enumeration. <br />
saturate: A saturation according the <code>vx_convert_policy_e</code> enumeration. The following equation is implemented: <br />
 \( outputs[j,k,i] = saturate(round(\sum_{l} \sum_{m,n}(inputs_{upscaled}[j+m,k+n,l] \times weights[m,n,l,i])+biasses[j,k,i])) \)<br />
Where \(m,n\) are indexes on the convolution matrices. \( l\) is an index on all the convolutions per input. \( i\) is an index per output. \( j,k \) are the inputs/outputs spatial indexes. Deconvolution is done on the width and height dimensions of the <code>vx_tensor</code>. Therefore, we use here the term x for the width dimension and y for the height dimension.<br />
before the Deconvolution is done, up-scaling the width and height dimensions with zeros is performed. The relation between input to output is as follows: <br />
 \( width_{output} = (width_{input} -1) * upscale_x - 2 * padding_x + kernel_x + a_x \)<br />
and <br />
 \( height_{output} = (height_{input} - 1) * upscale_y - 2 * padding_y + kernel_y + a_y \)<br />
 where \(width_{input}\) is the size of the input width dimension. \(height_{input}\) is the size of the input height dimension. \(width_{output}\) is the size of the output width dimension. \(height_{output}\) is the size of the output height dimension. \(kernel_x\) and \(kernel_y\) are the convolution sizes in width and height. \(a_x\) and \(a_y\) are user-specified quantity used to distinguish between the \(upscale_x\) and \(upscale_y\) different possible output sizes. \(upscale_x\) and \(upscale_y\) are calculated by the relation between input and output. \(a_x\) and \(a_y\) must be positive and smaller then \(upscale_x\) and \(upscale_y\) respectively. Since the padding parameter is on the output. The effective input padding is: <br />
 \( padding_{input_x} = kernel_x -padding_x -1\) <br />
 \( padding_{input_y} = kernel_y -padding_y -1\) <br />
Therfore the following constarints apply : \(kernel_x &gt;= padding_x - 1\) and \(kernel_y &gt;= padding_y - 1\). rounding is done according to <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a></code>. Notice that this node creation function has more parameters than the corresponding kernel. Numbering of kernel parameters (required if you create this node using the generic interface) is explicitly specified here. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor. 3 lower dimensions represent a single input, and an optional 4th dimension for batch of inputs. Dimension layout is [width, height, #IFM, #batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>. Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8' or 'KHR_NN_8 KHR_NN_16'. (Kernel parameter #0) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>[static] The 4d weights with dimensions [width, height, #IFM, #OFM]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>. (Kernel parameter #1) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>[static] Optional, ignored if NULL. The biases have one dimension [#OFM]. Implementations must support input tensor data type same as the inputs. (Kernel parameter #2) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">deconvolution_params</td><td>[static] Pointer to parameters of type <code><a class="el" href="../../d6/d9a/group__group__cnn.html#d9/d91/structvx__nn__deconvolution__params__t">vx_nn_deconvolution_params_t</a></code> (Kernel parameter #3) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">size_of_deconv_params</td><td>[static] Size in bytes of deconvolution_params. Note that this parameter is not counted as one of the kernel parameters. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">outputs</td><td>The output tensor. The output has the same number of dimensions as the input. (Kernel parameter #4)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
<a id="ga70f11e4a18658dd8753f9d8e009730b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga70f11e4a18658dd8753f9d8e009730b2">&#9670;&nbsp;</a></span>vxFullyConnectedLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxFullyConnectedLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_enum&#160;</td>
          <td class="paramname"><em>overflow_policy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_enum&#160;</td>
          <td class="paramname"><em>rounding_policy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Fully connected Convolutional Network Layer Node. </p>
<p>This function implement Fully connected Convolutional Network layers. For fixed-point data types, a fixed point calculation is performed with round and saturate according to the number of accumulator bits. The number of the accumulator bits are implementation defined, and should be at least 16.<br />
round: rounding according the <code>vx_round_policy_e</code> enumeration. <br />
saturate: A saturation according the <code>vx_convert_policy_e</code> enumeration. The equation for Fully connected layer:<br />
 \( outputs[i] = saturate(round(\sum_{j} (inputs[j] \times weights[j,i])+biasses[i])) \)<br />
Where \(j\) is a index on the input feature and \(i\) is a index on the output. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor data. There two possible input layouts:<ol type="1">
<li>[#IFM, #batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.</li>
<li>[width, height, #IFM, #batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code><br />
In both cases number of batches are optional and may be multidimensional. The second option is a special case to deal with convolution layer followed by fully connected. The dimension order is [#IFM, #batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>. Note that batch may be multidimensional. Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8' or 'KHR_NN_8 KHR_NN_16'. </li>
</ol>
</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>[static] Number of dimensions is 2. Dimensions are [#IFM, #OFM]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>.<br />
 Implementations must support input tensor data type same as the inputs. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>[static] Optional, ignored if NULL. The biases have one dimension [#OFM]. Implementations must support input tensor data type same as the inputs. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">overflow_policy</td><td>[static] A <code> VX_TYPE_ENUM</code> of the <code> vx_convert_policy_e</code> enumeration. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rounding_policy</td><td>[static] A <code> VX_TYPE_ENUM</code> of the <code> vx_round_policy_e</code> enumeration. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">outputs</td><td>The output tensor data. Output dimension layout is [#OFM,#batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>, where #batches may be multidimensional. Output tensor data type must be same as the inputs. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
<a id="ga2f2dd3b8c00370e78552ef64bb2a174c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2f2dd3b8c00370e78552ef64bb2a174c">&#9670;&nbsp;</a></span>vxNormalizationLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxNormalizationLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_enum&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>normalization_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_float32&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_float32&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Convolutional Network Normalization Layer Node. This function is optional for 8-bit extension with the extension string 'KHR_NN_8'. </p>
<p>Normalizing over local input regions. Each input value is divided by \( (1+\frac{\alpha}{n}\sum_i x^2_i)^\beta \) , where n is the number of elements to normalize across. and the sum is taken over a rectangle region centred at that value (zero padding is added where necessary). </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor data. 3 lower dimensions represent a single input, 4th dimension for batch of inputs is optional.Dimension layout is [width, height, IFM, #batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>. Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8 KHR_NN_16'. Since this function is optional for 'KHR_NN_8', so implementations only must support <code>VX_TYPE_INT16</code> with fixed_point_position 8. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">type</td><td>[static] Either same map or across maps (see <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga5edc475524c86e326b56ffaa7e8eaa28">vx_nn_norm_type_e</a></code>). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">normalization_size</td><td>[static] Number of elements to normalize across. Must be a positive odd number with maximum size of 7 and minimum of 3. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">alpha</td><td>[static] Alpha parameter in the normalization equation. must be positive. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">beta</td><td>[static] Beta parameter in the normalization equation. must be positive. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">outputs</td><td>The output tensor data. Output will have the same number of dimensions as input.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
<a id="gac4e286be0f9c9a2fbd3019fd74531332"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac4e286be0f9c9a2fbd3019fd74531332">&#9670;&nbsp;</a></span>vxPoolingLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxPoolingLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_enum&#160;</td>
          <td class="paramname"><em>pooling_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>pooling_size_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>pooling_size_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>pooling_padding_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>pooling_padding_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_enum&#160;</td>
          <td class="paramname"><em>rounding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Convolutional Network Pooling Layer Node. </p>
<p>Pooling is done on the width and height dimensions of the <code>vx_tensor</code>. Therefore, we use here the term x for the width dimension and y for the height dimension.<br />
Pooling operation is a function operation over a rectangle size and then a nearest neighbour down scale. Here we use pooling_size_x and pooling_size_y to specify the rectangle size on which the operation is performed. <br />
before the operation is done (average or maximum value). the data is padded with zeros in width and height dimensions . The down scale is done by picking the results according to a skip jump. The skip in the x and y dimension is determined by the output size dimensions. The first pixel of the down scale output is the first pixel in the input. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor data. 3 lower dimensions represent a single input, 4th dimension for batch of inputs is optional.Dimension layout is [width, height, #IFM, #batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code> Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8' or 'KHR_NN_8 KHR_NN_16'. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pooling_type</td><td>[static] Either max pooling or average pooling (see <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">vx_nn_pooling_type_e</a></code>). </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pooling_size_x</td><td>[static] Size of the pooling region in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pooling_size_y</td><td>[static] Size of the pooling region in the y dimension. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pooling_padding_x</td><td>[static] Padding size in the x dimension. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pooling_padding_y</td><td>[static] Padding size in the y dimension. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rounding</td><td>[static] Rounding method for calculating output dimensions. See <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga86bbe62218962d22af01d434a42603c6">vx_nn_rounding_type_e</a></code> </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">outputs</td><td>The output tensor data. Output will have the same number of dimensions as input. Output tensor data type must be same as the inputs. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
<a id="gae80cce7ad61e5b4ac9e1c1136f40d65e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae80cce7ad61e5b4ac9e1c1136f40d65e">&#9670;&nbsp;</a></span>vxROIPoolingLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxROIPoolingLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>input_rois</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="../../d6/d9a/group__group__cnn.html#d6/d8c/structvx__nn__roi__pool__params__t">vx_nn_roi_pool_params_t</a> *&#160;</td>
          <td class="paramname"><em>roi_pool_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_size&#160;</td>
          <td class="paramname"><em>size_of_roi_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>output_arr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Convolutional Network ROI pooling node </p>
<p>Pooling is done on the width and height dimensions of the <code>vx_tensor</code>. The ROI Pooling get an array of roi rectangles, and an input tensor. The kernel crop the width and height dimensions of the input tensor with the ROI rectangles and down scale the result to the size of the output tensor. The output tensor width and height are the pooled width and pooled height. The down scale method is determined by the pool_type. Notice that this node creation function has more parameters than the corresponding kernel. Numbering of kernel parameters (required if you create this node using the generic interface) is explicitly specified here. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor data. 3 lower dimensions represent a single input, 4th dimension for batch of inputs is optional. Dimension layout is [width, height, #IFM, #batches]. See <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>. Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8' or 'KHR_NN_8 KHR_NN_16'. (Kernel parameter #0) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs_rois</td><td>The roi array tensor. ROI array with dimensions [4, roi_count, #batches] where the first dimension represents 4 coordinates of the top left and bottom right corners of the roi rectangles, based on the input tensor width and height. #batches is optional and must be the same as in inputs. roi_count is the number of ROI rectangles. (Kernel parameter #1) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pool_type</td><td>[static] Of type <code><a class="el" href="../../d6/d9a/group__group__cnn.html#ga516b0d3e8da43e82826bcccfc196c3e2">vx_nn_pooling_type_e</a></code>. Only <code><a class="el" href="../../d6/d9a/group__group__cnn.html#gga516b0d3e8da43e82826bcccfc196c3e2abf630f40a139dfeb5349b7ece00725bc">VX_NN_POOLING_MAX</a></code> pooling is supported. (Kernel parameter #2) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">size_of_roi_params</td><td>[static] Size in bytes of roi_pool_params. Note that this parameter is not counted as one of the kernel parameters. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output_arr</td><td>The output tensor. Output will have [output_width, output_height, #IFM, #batches] dimensions. #batches is optional and must be the same as in inputs. (Kernel parameter #3)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
<a id="ga76a3a94a73992017519d7dc01e81c476"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga76a3a94a73992017519d7dc01e81c476">&#9670;&nbsp;</a></span>vxSoftmaxLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">vx_node vxSoftmaxLayer </td>
          <td>(</td>
          <td class="paramtype">vx_graph&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">vx_tensor&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>[Graph] Creates a Convolutional Network Softmax Layer Node. </p>
<p>the softmax function, is a generalization of the logistic function that "squashes" a K-dimensional vector \( z \) of arbitrary real values to a K-dimensional vector \( \sigma(z) \) of real values in the range (0, 1) that add up to 1. The function is given by: \( \sigma(z) = \frac{\exp^z}{\sum_i \exp^{z_i}} \) </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">graph</td><td>The handle to the graph. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inputs</td><td>The input tensor, with the number of dimensions according to the following scheme. In case IFM dimension is 1. Softmax is be calculated on that dimension. In case IFM dimension is 2. Softmax is be calculated on the first dimension. The second dimension is batching. In case IFM dimension is 3. Dimensions are [Width, Height, Classes]. And Softmax is calculated on the third dimension. In case IFM dimension is 4. Dimensions are [Width, Height, Classes, batching]. Softmax is calculated on the third dimension. Regarding the layout specification, see <code>vxCreateTensor</code> and <code>vxCreateVirtualTensor</code>. In all cases Implementations must support input tensor data types indicated by the extension strings 'KHR_NN_8' or 'KHR_NN_8 KHR_NN_16'. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">outputs</td><td>The output tensor. Output will have the same number of dimensions as input. Output tensor data type must be same as the inputs.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><code> vx_node</code>. </dd>
<dd>
A node reference <code>vx_node</code>. Any possible errors preventing a successful creation should be checked using <code>vxGetStatus</code>. </dd></dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Wed Nov 8 2017 12:35:16 for OpenVX Neural Network Extension by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="../../doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
